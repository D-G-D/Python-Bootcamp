{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73ce8c84",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f57ba0",
   "metadata": {},
   "source": [
    "Cleaning data is a tedious, often manual process. While some steps can be automated, often we will need to find the discrepancies between the expected data (format, content...) and the actual data.  Common issues include:\n",
    "- Wrong data type\n",
    "    - Integers loaded as floats (pandas issue).\n",
    "    - Including float rounding differences.\n",
    "    - Dates not loaded as dates.    \n",
    "    \n",
    "- Data not conforming to data type\n",
    "    - Isolated values with different data types vs the rest of their column\n",
    "    - Wrong numeric data (dollar sign included, decimal, separator)\n",
    "    \n",
    "- Wrong input values  \n",
    "    - Wrong number format (Year loaded as 17 instead of 2017)\n",
    "    - Repeated strings, similar\n",
    "   \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    - \n",
    "- Missing data\n",
    "    - Emtpy values\n",
    "    - Unknown, null and other strings\n",
    "- Duplicates\n",
    "- Simplification of data\n",
    "\n",
    "\n",
    "For example, we might have a column with Euro values saved as a number (e.g. `1000`) but some values stored with the Euro sign (`€1000`). In that case, if we want to keep the column as a number, we need to remove the `€`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edb5973",
   "metadata": {},
   "source": [
    "Objective:\n",
    "- Enough data for analysis\n",
    "- Reduce the number of years to keep file small\n",
    "- Eliminate non-core columns with limited data (many nulls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9872c41e",
   "metadata": {},
   "source": [
    "> What is difficult, it is manual\n",
    "\n",
    "> Load the parties_data file, only if no local copy exists\n",
    "\n",
    "> create this file without being \"corrected\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65cf739",
   "metadata": {},
   "source": [
    "# Initial load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a629ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'TCCSF_parties_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdec5ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d878b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dirkg\\AppData\\Local\\Temp\\ipykernel_3804\\707990406.py:1: DtypeWarning: Columns (3,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_name)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31d7013",
   "metadata": {},
   "source": [
    "Importing the data without further arguments can lead to some errors or warnings. Here, Pandas is complaining about some specific column types. When loading a dataset, Pandas will try guessing the data type of each column. To avoid the warning, we can force the data type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c854773b",
   "metadata": {},
   "source": [
    "> Add more info about the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50d6fb07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['case_id_pkey', 'juris'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[[3, 15]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c780a6d",
   "metadata": {},
   "source": [
    "Those columns were supposed to be numbers. The error is raised when Pandas encounters just a few values that do not match the type that could suit most of the values. In those cases, we load the data as strings, and later analyse and fix the issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6337619d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    131045181\n",
       "1      2008108\n",
       "2      5469799\n",
       "3    210012766\n",
       "4      5590027\n",
       "Name: case_id_pkey, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:5,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9efc19",
   "metadata": {},
   "source": [
    "Short exploration confirms it. Is that always the case? If dtype is object, it is likely there is at least one row that has a value that couldn't be converted to an integer. Let's explore which one, how many..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c1f1c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "forced_types = {'case_id_pkey': str, 'juris': str}\n",
    "df = pd.read_csv(file_name, dtype=forced_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbfcb3c",
   "metadata": {},
   "source": [
    "If we want, we can also select a specific column (or set of columns) to be the index. In this case, since `unique_id` (column 0) is the primary key of the data, we will load it as index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "663c845c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_name, index_col=0, dtype={'case_id_pkey': str, 'juris': str})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee532e8",
   "metadata": {},
   "source": [
    "One more thing, you might work with datasets containing characters such as ñ, ü, è, etc. that require a different encoding. If that is the case (not here) you need to select the right encoding when using `read_csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ddbc7eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cnn_intrsctn_fkey', 'cnn_sgmt_fkey', 'case_id_pkey', 'tb_latitude',\n",
       "       'tb_longitude', 'geocode_source', 'geocode_location',\n",
       "       'collision_datetime', 'collision_date', 'collision_time',\n",
       "       'accident_year', 'month', 'day_of_week', 'time_cat', 'juris',\n",
       "       'officer_id', 'reporting_district', 'beat_number', 'primary_rd',\n",
       "       'secondary_rd', 'distance', 'direction', 'weather_1', 'weather_2',\n",
       "       'collision_severity', 'type_of_collision', 'mviw', 'ped_action',\n",
       "       'road_surface', 'road_cond_1', 'road_cond_2', 'lighting',\n",
       "       'control_device', 'intersection', 'vz_pcf_code', 'vz_pcf_group',\n",
       "       'vz_pcf_description', 'vz_pcf_link', 'number_killed', 'number_injured',\n",
       "       'street_view', 'dph_col_grp', 'dph_col_grp_description',\n",
       "       'party_number_ckey', 'party_type', 'at_fault', 'party_sex', 'party_age',\n",
       "       'party_sobriety', 'party_drug_physical', 'dir_of_travel',\n",
       "       'party_safety_equip_1', 'party_safety_equip_2', 'finan_respons',\n",
       "       'sp_info_1', 'sp_info_2', 'sp_info_3', 'oaf_viol_cat',\n",
       "       'oaf_viol_section', 'oaf_violation_code', 'oaf_violation_suffix',\n",
       "       'oaf_1', 'oaf_2', 'party_number_killed', 'party_number_injured',\n",
       "       'move_pre_acc', 'vehicle_year', 'vehicle_make', 'stwd_vehicle_type',\n",
       "       'race', 'inattention', 'special_info_f', 'special_info_g',\n",
       "       'street_of_travel', 'vehicle_autonomous', 'point', 'data_as_of',\n",
       "       'data_updated_at', 'data_loaded_at', 'analysis_neighborhood',\n",
       "       'supervisor_district', 'police_district', 'Current Police Districts',\n",
       "       'Current Supervisor Districts', 'Analysis Neighborhoods',\n",
       "       'Neighborhoods', 'SF Find Neighborhoods'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000ba588",
   "metadata": {},
   "source": [
    "# Drop unnecessary data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868fd57a",
   "metadata": {},
   "source": [
    "To avoid working with unnecessarily big datasets, we should first drop the data we do not need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "105c765c",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['geocode_source', # Source of Lat/Lon; not needed for the project\n",
    "                'geocode_location',  # Source of Lat/Lon; not needed for the project\n",
    "                'intersection', # Not needed. we can use distance and type_of_colision\n",
    "                'juris', # Jurisdiction not useful for project analysis\n",
    "                'reporting_district', # Multiple values used one; doesn't add to analysis\n",
    "                'beat_number', # Multiple values used one; doesn't add to analysis\n",
    "                'SF Find Neighborhoods', # Not keeping neighborhood data (too granular + definitions not 100% clear)\n",
    "                'Neighborhoods', # Not keeping neighborhood data (too granular + definitions not 100% clear)\n",
    "                'Analysis Neighborhoods', # Not keeping neighborhood data (too granular + definitions not 100% clear)\n",
    "                'analysis_neighborhood', # Not keeping neighborhood data (too granular + definitions not 100% clear)\n",
    "                'data_as_of', # For the analysis we don't need metadata on the entries\n",
    "                'data_updated_at', # For the analysis we don't need metadata on the entries\n",
    "                'data_loaded_at', # For the analysis we don't need metadata on the entries\n",
    "                'point', # Alternative to lat/Lon\n",
    "                'collision_date', # Redundant when having collision_datetime\n",
    "                'collision_time', # Redundant when having collision_datetime\n",
    "                'accident_year', # Redundant when having collision_datetime\n",
    "                'month', # Redundant when having collision_datetime\n",
    "                'day_of_week', # Redundant when having collision_datetime\n",
    "                'vz_pcf_code', # vz_pcf_description is enough\n",
    "                'vz_pcf_group', # vz_pcf_description is enough\n",
    "                'vz_pcf_link', # vz_pcf_description is enough\n",
    "                'number_killed', # redundant since we have party_number_killed\n",
    "                'number_injured', # redundant since we have party_number_injured\n",
    "                'street_view', # Can be built with lat/lon\n",
    "                'dph_col_grp', # dph_col_grp_description is enough\n",
    "                'cnn_intrsctn_fkey', # Cannot really relate it to the primary road, and no table with this as pkey\n",
    "                'cnn_sgmt_fkey',\n",
    "               'supervisor_district', # old district info\n",
    "               'police_district',  # old district info\n",
    "                'time_cat' # 4h-group of time of the day; redundant\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43d230eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128027, 56)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=drop_columns, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cad5065",
   "metadata": {},
   "source": [
    "We could also have simply not loaded the data when reading from the CSV using a parameter for `read_csv`. Make sure to add those columns you want to use as index to the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6376623",
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_columns = ['unique_id', 'case_id_pkey', 'tb_latitude', 'tb_longitude', 'collision_datetime',\n",
    "       'officer_id', 'primary_rd', 'secondary_rd', 'distance', 'direction',\n",
    "       'weather_1', 'weather_2', 'collision_severity', 'type_of_collision',\n",
    "       'mviw', 'ped_action', 'road_surface', 'road_cond_1', 'road_cond_2',\n",
    "       'lighting', 'control_device', 'vz_pcf_description', 'dph_col_grp_description', 'party_number_ckey',\n",
    "       'party_type', 'at_fault', 'party_sex', 'party_age', 'party_sobriety',\n",
    "       'party_drug_physical', 'dir_of_travel', 'party_safety_equip_1',\n",
    "       'party_safety_equip_2', 'finan_respons', 'sp_info_1', 'sp_info_2',\n",
    "       'sp_info_3', 'oaf_viol_cat', 'oaf_viol_section', 'oaf_violation_code',\n",
    "       'oaf_violation_suffix', 'oaf_1', 'oaf_2', 'party_number_killed',\n",
    "       'party_number_injured', 'move_pre_acc', 'vehicle_year', 'vehicle_make',\n",
    "       'stwd_vehicle_type', 'race', 'inattention', 'special_info_f',\n",
    "       'special_info_g', 'street_of_travel', 'vehicle_autonomous',\n",
    "       'Current Police Districts', 'Current Supervisor Districts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b177ef92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128027, 56)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(file_name, index_col='unique_id', dtype={'case_id_pkey': str}, usecols=useful_columns)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef0d3da",
   "metadata": {},
   "source": [
    "In any case, it is useful to know that columns can be dropped from the dataset. We might want to use their data as part of the cleaning process, but remove them at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350e485c",
   "metadata": {},
   "source": [
    "# Fix format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506dec6d",
   "metadata": {},
   "source": [
    "We will first fix the data format of the remaining columns. Pandas will default to type `object`, that is a set of characters. We could have forced some data types at the beginning when loading the data, but the advantage of doing it later is that we can inspect the data. In some cases we won't be able to set the desired type because of wrong data. For example, we might have a column with Euro values saved as a number (e.g. `1000`) but some values stored with the Euro sign (`€1000`). In that case, if we want to keep the column as a number, we need to remove the `€`. Let's look at all the types:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cedcf0",
   "metadata": {},
   "source": [
    "## Columns that should be integers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209039eb",
   "metadata": {},
   "source": [
    "> Integrated the following code in each section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06dfa56",
   "metadata": {},
   "source": [
    "int_columns = ['Current Supervisor Districts', \n",
    "               'Current Police Districts', \n",
    "               #'distance', \n",
    "               #'number_killed', \n",
    "               'vehicle_year',\n",
    "               #'party_age']\n",
    "#   df[column] = df[column].astype(pd.Int64Dtype())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15015e5",
   "metadata": {},
   "source": [
    "# Issues with columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191590e9",
   "metadata": {},
   "source": [
    "## Column `case_id_pkey`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80bb79e",
   "metadata": {},
   "source": [
    "This is a case of having isolated values with different data types vs the rest of their column. First, let's identify those cases that do not conform to our expectations. Pandas wanted to convert to numbers, yet it found a few values that couldn't (hence the warning with `read_csv`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c87ce78e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_non_numeric = pd.to_numeric(df['case_id_pkey'], errors='coerce').isna()\n",
    "mask_non_numeric.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d00d08dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128027"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e47432",
   "metadata": {},
   "source": [
    "That is only 4 cases out of 128.027 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52a71d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['210072867`', '9335-2020-00557']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values_non_numeric = list(df['case_id_pkey'][mask_non_numeric].unique())\n",
    "values_non_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb10828",
   "metadata": {},
   "source": [
    "As we see, we have 4 rows, but only 2 different issues. In the first case, a non-digit character is added at the end, likely a mistake. In the second, dashes are added as probably that is how the case ID is sometimes formatted. An obvious option here is to remove the non-digit characters, but before that, we should verify if any rows exist with the resulting values, and if they do, if they \"look\" like they are the same case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8af19579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['210072867', '9335202000557']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_values = df['case_id_pkey'][mask_non_numeric].str.replace(r'\\D+', '', regex=True)\n",
    "values_numeric = list(modified_values.unique())\n",
    "values_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73a03f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_numeric = df['case_id_pkey'].isin(values_numeric)\n",
    "mask_numeric.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e16d4ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['210072867']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df['case_id_pkey'][mask_numeric].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9940c82",
   "metadata": {},
   "source": [
    "There are two rows that already contain `case_id_pkey` equal to `210072867`. Let's change the values to remove the non-digit values, and then verify how the rows with that case number look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72e3717c",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = modified_values.index\n",
    "columns = ['case_id_pkey']\n",
    "df.loc[indexes, columns] = modified_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2cb1789d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unique_id\n",
       "627345    False\n",
       "627346    False\n",
       "632567    False\n",
       "632566    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['case_id_pkey'] == '210072867'].duplicated()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1060cdf0",
   "metadata": {},
   "source": [
    "After removing from the `case_id_pkey` the non-digit character, the rows for case `210072867` are duplicated. No further action is required now, since we will remove duplicated rows at a later stage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e249611",
   "metadata": {},
   "source": [
    "## Columns `tb_latitude` and `tb_longitude`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bae2b4",
   "metadata": {},
   "source": [
    "An issue with `float` numbers is that they might have too many decimal points for our needs, and two numbers that should be the same are stored differently. For example, in this data set we have latitude and longitude. We don't need more than 6 decimals to have a decent precision. Let's look at an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f08bc7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unique_id\n",
       "627345    37.769483\n",
       "632567    37.769483\n",
       "Name: tb_latitude, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_indexes = [627345, 632567]\n",
    "df.loc[study_indexes, 'tb_latitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82df0943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tb_latitude\n",
       "37.769483    1\n",
       "37.769483    1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[study_indexes, 'tb_latitude'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602658b9",
   "metadata": {},
   "source": [
    "They look the same, right? They are to you, but internally there are small differences that Python is not showing when rounding the number for display..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2f82ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.416289473534562e-11"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weird_values = df.loc[study_indexes, 'tb_latitude'].unique()\n",
    "weird_values[0] - weird_values[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaed3509",
   "metadata": {},
   "source": [
    "The difference is smaller than one millionth of a degree. It is, in fact, a data issue. To avoid this, we will round the two columns and check that the issue has been resolved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d0c87d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['tb_latitude', 'tb_longitude']:\n",
    "    df[column] = df[column].round(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7461c532",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tb_latitude\n",
       "37.769483    2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[study_indexes, 'tb_latitude'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b1a349",
   "metadata": {},
   "source": [
    "We have already fixed part of the issue with this column by rounding the `float` values. We should verify that the values are correct, and no point is far outside the city of San Francisco. An option would be to plot the points, but to avoid installing additional packages, we will simply check the minimum and maximum values.\n",
    "\n",
    "The approximate boundaries of the city are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "20f27374",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lat = 37.8324\n",
    "min_lat = 37.7081\n",
    "max_lon = -122.3570\n",
    "min_lon = -123.1738"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f2b1e345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tb_latitude'].describe()['max'] < max_lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0003e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tb_latitude'].describe()['min'] > min_lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "32a95d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.707459"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tb_latitude'].describe()['min'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a12b9aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-122.4629])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['tb_latitude']== 37.707459]['tb_longitude'].drop_duplicates().values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8da32a",
   "metadata": {},
   "source": [
    "There is a small discrepancy between our boundary and the smallest number. If we check the coordinates we'll find that the address corresponds to Daly City, just south of San Francisco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "785bf672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tb_longitude'].describe()['max'] < max_lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e6e96260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tb_longitude'].describe()['min'] > min_lon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b351b7",
   "metadata": {},
   "source": [
    "## Column `collision_datetime`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "43d2f33a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unique_id\n",
       "36115     12/12/2013 02:05:00 PM\n",
       "2178      04/14/2005 04:20:00 PM\n",
       "28980     01/22/2012 07:46:00 PM\n",
       "627682    01/06/2021 05:45:00 PM\n",
       "29244     02/22/2012 10:02:00 PM\n",
       "Name: collision_datetime, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['collision_datetime'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba905d68",
   "metadata": {},
   "source": [
    "As we can observe, the string stores de day, month, year and time of the incident. In case we need to manipulate this as a date, it is useful to transform it to a `datetime64[ns]` format. This will be useful only while working with Pandas, after we export the clean CSV file, the date will be stored as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8571b1c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unique_id\n",
       "36115    2013-12-12 14:05:00\n",
       "2178     2005-04-14 16:20:00\n",
       "28980    2012-01-22 19:46:00\n",
       "627682   2021-01-06 17:45:00\n",
       "29244    2012-02-22 22:02:00\n",
       "Name: collision_datetime, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['collision_datetime'] = pd.to_datetime(df['collision_datetime'], format='%m/%d/%Y %I:%M:%S %p')\n",
    "df['collision_datetime'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a07c64fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "min    2005-01-01 01:15:00\n",
       "max    2024-10-31 22:00:00\n",
       "Name: collision_datetime, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['collision_datetime'].describe()[['min', 'max']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca660fbe",
   "metadata": {},
   "source": [
    "Data starts on year 2005... and should end July 2024, when the data was extracted. Here, we could limit our data to the date when we extracted the data. However, since we want to reduce the size of the output file to less than 25MB (so we can upload to GitHub), we will need to further reduce the size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "666f0b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51531, 56)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_year = 2016\n",
    "max_year = 2023\n",
    "df = df[(df['collision_datetime'].dt.year >= min_year) & (df['collision_datetime'].dt.year <= max_year)]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42e6c26",
   "metadata": {},
   "source": [
    "We can easily revisit the upper and lower limit boundary of our dataset if at the end of the process the file is still too large."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d975eaa4",
   "metadata": {},
   "source": [
    "## Column `officer_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9e298156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "officer_id\n",
       "2375           283\n",
       "1994           270\n",
       "4314           242\n",
       "2132           201\n",
       "4286           195\n",
       "              ... \n",
       "1785             1\n",
       "#2732            1\n",
       "824              1\n",
       "GODOY#02202      1\n",
       "4225             1\n",
       "Name: count, Length: 2086, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['officer_id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e044ad3d",
   "metadata": {},
   "source": [
    "We see over 2000 different officer ID values. Just looking at the values printed on screen we could guess some issues. For example, there is an officer with id `#2732`. The hash is often used as a replacement for the word \"number\", so... do we have any reports from officer `2732` (without hash)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "90bce594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['officer_id'] == '2732').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1411f9a6",
   "metadata": {},
   "source": [
    "Yes. We do. Let's see how many officer ids contain the non-numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4d4b72e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_contains_other = ~ (df['officer_id'].str.isdigit().fillna(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "723b1ee2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "officer_id\n",
       "#1118         97\n",
       "#2008         78\n",
       "#2450         41\n",
       "#2035         24\n",
       "#1500         23\n",
       "              ..\n",
       "#1533          1\n",
       "#2359          1\n",
       "171 & 1387     1\n",
       "#2732          1\n",
       "#364           1\n",
       "Name: count, Length: 417, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['officer_id'][mask_contains_other].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7aa003",
   "metadata": {},
   "source": [
    "That is 417 out of 2086 different values. This inspection shows two things:\n",
    "1. Several cases include the `#`. We should remove it to have the same format.\n",
    "2. There are cases that the user entered two numbers: `171 & 1387`. For now, let's treat those as an independent id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b97786e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['officer_id'] = df['officer_id'].str.replace('#','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d9b9fe5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_contains_other = ~ (df['officer_id'].str.isdigit().fillna(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8eafcfe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "officer_id\n",
       "A22028        21\n",
       "Li 1074       20\n",
       "A20952        20\n",
       "A09968        19\n",
       "A23073        17\n",
       "              ..\n",
       "HAWES 4281     1\n",
       "ANTON 2179     1\n",
       "A20831         1\n",
       "A07632         1\n",
       "A22397         1\n",
       "Name: count, Length: 274, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['officer_id'][mask_contains_other].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d88b156",
   "metadata": {},
   "source": [
    "New cases appear: officers write their name before the number, or an \"A\". Can we assume that the letter A is redundant here? Should those officers without an A have written the A? When doing data cleaning, often we need knowledge not available in our data.\n",
    "\n",
    "We will *assume* that any non-number before the number is not part of the officer ID. Not all of them though, as we don't want to eliminate the spaces and \"&\" between the case `171 & 1387` and turn it into a new number (`1711387`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1bd16b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_values = df['officer_id'][mask_contains_other].str.replace(r'^\\D*(?=\\d)', '', regex=True)\n",
    "indexes = modified_values.index\n",
    "columns = ['officer_id']\n",
    "df.loc[indexes, columns] = modified_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d521315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_contains_other = ~ (df['officer_id'].str.isdigit().fillna(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dd8f33c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "officer_id\n",
       "Li                10\n",
       "Chicas, M.         9\n",
       "ALVENDIA           7\n",
       "FYLES              7\n",
       "P. Rechsteiner     7\n",
       "                  ..\n",
       "HERERRA            2\n",
       "VARGAS             2\n",
       "20:22              2\n",
       "3E15D              2\n",
       "171 & 1387         1\n",
       "Name: count, Length: 88, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['officer_id'][mask_contains_other].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4ef943a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1846"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['officer_id'].value_counts().shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6272056",
   "metadata": {},
   "source": [
    "Since there were some cases with name and number (like `Li 1074`) we could try to further link those values; we could replace those ids only with name, with the number (for example `Li` becomes `1074`). However, not having a full database we could be confusing two officers with the same name. Hence, we stop here. We have reduced the number of different values to 1846, and only 88 of those are not formatted as a just a number."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2327e0b",
   "metadata": {},
   "source": [
    "We check if there are any strings that indicate no value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6b737555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['officer_id'].str.title().isin(['Unknown', 'Not Stated']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2e79cd",
   "metadata": {},
   "source": [
    "## Column `primary_rd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b4f95b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "primary_rd\n",
       "MISSION ST               2296\n",
       "MARKET ST                1504\n",
       "VAN NESS AVE             1127\n",
       "03RD ST                  1059\n",
       "GEARY BLVD                866\n",
       "                         ... \n",
       "WETMORE ST                  1\n",
       "HIGUERA AVE                 1\n",
       "LECH WALESA ST              1\n",
       "SAN JOSE AVE OFF RAMP       1\n",
       "ROSENKRANZ ST               1\n",
       "Name: count, Length: 947, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['primary_rd'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7bfb0969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "primary_rd\n",
       "GELLERT DR               1\n",
       "BELGRAVE AVE             1\n",
       "CERRITOS AVE             1\n",
       "RIVAS AVE                1\n",
       "LASKIE ST                1\n",
       "WETMORE ST               1\n",
       "HIGUERA AVE              1\n",
       "LECH WALESA ST           1\n",
       "SAN JOSE AVE OFF RAMP    1\n",
       "ROSENKRANZ ST            1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['primary_rd'].value_counts().tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8555434d",
   "metadata": {},
   "source": [
    "Looking at the `value_counts()`, we observe 947 different street names. Issues aren't obvious. Even looking the last 10 cases we don't see an immediate big issue. Two things stand out:\n",
    "1. `GELLERT DR` has no `ST` or `AVE` in it, unlike all other options.\n",
    "2. `SAN JOSE AVE OFF RAMP` has the \"off ramp\" part that comes after avenue. Might there be a San Jose Avenue without the offramp?\n",
    "\n",
    "Let's start investigating there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "683b8d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "primary_rd\n",
       "GELLERT DR    1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_gellert = df['primary_rd'].str.contains('GELLERT')\n",
    "df['primary_rd'][mask_gellert].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fcdab73a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "primary_rd\n",
       "SAN JOSE AVE             444\n",
       "SAN JOSE AV OFF RAMP       3\n",
       "SAN JOSE AVE OFF RAMP      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_san_jose = df['primary_rd'].str.contains('SAN JOSE')\n",
    "df['primary_rd'][mask_san_jose].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "67d86aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "primary_rd\n",
       "HWY 101 S OFF RAMP              12\n",
       "BAY SHORE BLVD OFF RAMP          7\n",
       "JUNIPERO SERRA BLVD OFF RAMP     6\n",
       "I-280 N OFF RAMP                 4\n",
       "HWY 101 N OFF RAMP               4\n",
       "I-280 S OFF RAMP                 3\n",
       "ALEMANY BLVD OFF RAMP            3\n",
       "SAN JOSE AV OFF RAMP             3\n",
       "INDUSTRIAL ST OFF RAMP           1\n",
       "SAN JOSE AVE OFF RAMP            1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_off_ramp = df['primary_rd'].str.contains('OFF RAMP')\n",
    "df['primary_rd'][mask_off_ramp].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df94520c",
   "metadata": {},
   "source": [
    "There seems to be no issue with `GELLERT`, but we observe that several streets names also refer to the off ramp. The choice of adding `OFF RAMP` is repeated a few times, and it adds additional information. Thus, we will leave it as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3d805206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "primary_rd\n",
       "SAN JOSE AV OFF RAMP    3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_av_only = df['primary_rd'].str.contains(' AV') & (~df['primary_rd'].str.contains(' AVE'))\n",
    "df['primary_rd'][mask_av_only].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9911cd",
   "metadata": {},
   "source": [
    "The typo in `SAN JOSE AV OFF RAMP` (missing an \"E\") only happens for one road."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3f51c5a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "primary_rd\n",
       "SAN JOSE AVE             444\n",
       "SAN JOSE AVE OFF RAMP      4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['primary_rd'] = df['primary_rd'].str.replace('SAN JOSE AV OFF RAMP', 'SAN JOSE AVE OFF RAMP')\n",
    "df['primary_rd'][mask_san_jose].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25a6525",
   "metadata": {},
   "source": [
    "A more scalable way to check this is finding if there are any combinations of street names that differ slightly. We will exclude those streets that are simply a number street/avenue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a50c74d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_study = df['primary_rd'].copy().drop_duplicates()\n",
    "for elem in ['ST ST', 'ND ST', 'RD ST', 'TH ST', 'ST AVE', 'ND AVE', 'RD AVE', 'TH AVE']:\n",
    "    pattern = rf'\\b\\d{{2}}{elem}\\b'\n",
    "    index = df_study[df_study.str.contains(pattern, na=False)].index\n",
    "    df_study.drop(index, inplace=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238b5c91",
   "metadata": {},
   "source": [
    "We can control the similarity using the `threshold`. The closer it is to 1, the more similar the stirngs must be. Given that some names are very similar despite being different streets (like one street containing the word \"east\" and another \"west\"). There are other mechanisms to find similarities. In a case like this, we would very likely need some manual checking, or at least using additional map libraries to check the coordinates. The code below is shared as an example, but the values are not further changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "173876e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MISSION ST', 'MISSION ST.']\n",
      "['NORTH POINT ST', 'NORTHPOINT ST']\n",
      "['ALEMANY BLVD WEST', 'ALEMANY BLVD EAST']\n",
      "['ALEMANY BLVD', 'AELMANY BLVD']\n",
      "['TERRY A FRANCOIS BLVD', 'TERRY FRANCOIS BLVD']\n",
      "['HWY 101 S OFF RAMP', 'HWY 101 S ON RAMP']\n",
      "['HWY 101 S OFF RAMP', 'HWY 101 N OFF RAMP']\n",
      "['09TH TI ST', '9TH TI ST']\n",
      "['HWY 101 N ON RAMP', 'HWY 101 S ON RAMP']\n",
      "['HWY 101 N ON RAMP', 'HWY 101 N OFF RAMP']\n",
      "['MISSION BAY BLVD NORTH', 'MISSION BAY BLVD SOUTH']\n",
      "['JUNIPERO SERRA BLVD OFF RAMP', 'JUNIPERO SERRA BLVD ON RAMP']\n",
      "['JUNIPERO SERRA BLVD OFF RAMP', 'JUNIPERO SERRA  BLVD ON RAMP']\n",
      "['LAKE ST', 'BLAKE ST']\n",
      "['BAY SHORE BLVD EXT', 'BAY SHORE BLVD EAST']\n",
      "['EL CAMINO DEL MAR', 'CAMINO DEL MAR']\n",
      "['MISSION BAY SOUTH BLVD', 'MISSION BAY NORTH BLVD']\n",
      "['TENNESSEE ST', 'GENNESSEE ST']\n",
      "['MARIN ST', 'MAIN ST']\n",
      "['I-280 S OFF RAMP', 'I-280 S ON RAMP']\n",
      "['I-280 S OFF RAMP', 'I-280 N OFF RAMP']\n",
      "['I-280 S ON RAMP', 'I-280 N ON RAMP']\n",
      "['CHESTER AVE', 'HESTER AVE']\n",
      "['EDINBURGH ST', 'EDINBURG ST']\n",
      "['JUNIPERO SERRA BLVD ON RAMP', 'JUNIPERO SERRA  BLVD ON RAMP']\n",
      "['I-280 N OFF RAMP', 'I-280 N ON RAMP']\n"
     ]
    }
   ],
   "source": [
    "import difflib\n",
    "for i in range(len(df_study)):\n",
    "    for j in range(i+1, len(df_study)):\n",
    "        ratio = difflib.SequenceMatcher(None, df_study.iloc[i], df_study.iloc[j]).ratio()\n",
    "        if ratio > 0.9 and ratio < 1:\n",
    "            print([df_study.iloc[i], df_study.iloc[j]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1062ee",
   "metadata": {},
   "source": [
    "We check if there are any strings that indicate no value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "db0285f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['primary_rd'] == 'UNKNOWN').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "19f6b227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['primary_rd'] == 'NOT STATED').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "80cfd1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['primary_rd'] == 'UNKNOWN', 'primary_rd'] = 'Not Stated'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecdeb6a",
   "metadata": {},
   "source": [
    "## Column `secondary_rd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8351328a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "secondary_rd\n",
       "MISSION ST               818\n",
       "FOLSOM ST                564\n",
       "HARRISON ST              532\n",
       "VAN NESS AVE             523\n",
       "16TH ST                  509\n",
       "                        ... \n",
       "EAGLE ST                   1\n",
       "WOODACRE DR                1\n",
       "HILL POINT AVE             1\n",
       "LIGHT POLE USED AS RP      1\n",
       "WHITING WAY                1\n",
       "Name: count, Length: 1425, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['secondary_rd'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9163a10b",
   "metadata": {},
   "source": [
    "We could do the same approach as with the primary road. In this case, the issues are different, so we will only fix the nulls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "768e08a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['secondary_rd'].str.upper() == 'UNKNOWN', 'secondary_rd'] = 'Not Stated'\n",
    "df.loc[df['secondary_rd'].str.upper() == 'NOT STATED', 'secondary_rd'] = 'Not Stated'\n",
    "df.loc[df['secondary_rd'].isna(), 'secondary_rd'] = 'Not Stated'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342f4ecf",
   "metadata": {},
   "source": [
    "## Column `distance`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ecca7647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unique_id\n",
       "626976    0.0\n",
       "48588     1.0\n",
       "245780    2.0\n",
       "88470     3.0\n",
       "47420     4.0\n",
       "48178     5.0\n",
       "87181     6.0\n",
       "626600    7.0\n",
       "634125    8.0\n",
       "88930     9.0\n",
       "Name: distance, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['distance'].drop_duplicates().sort_values().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b332e9",
   "metadata": {},
   "source": [
    "We will convert the column integers. Pandas chose a `float64` type not because it detected decimals, but because there were null values (see the *not a number* above, or `nan`) as `int64` does not accept nulls. If we integers, we can use `pd.Int64Dtype()`. Having an integer type is useful in case we need to do manipulation during the cleaning process, and to avoid unnecessary bigger files by storing the decimal (always `.0`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "22ecf6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['distance'] = df['distance'].astype(pd.Int64Dtype())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b70caabf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unique_id\n",
       "626976    0\n",
       "48588     1\n",
       "245780    2\n",
       "88470     3\n",
       "47420     4\n",
       "48178     5\n",
       "87181     6\n",
       "626600    7\n",
       "634125    8\n",
       "88930     9\n",
       "Name: distance, dtype: Int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['distance'].drop_duplicates().sort_values().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2551ad8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       51500.0\n",
       "mean      49.395631\n",
       "std      155.505221\n",
       "min             0.0\n",
       "25%             0.0\n",
       "50%             0.0\n",
       "75%            50.0\n",
       "max         13925.0\n",
       "Name: distance, dtype: Float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['distance'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7576e496",
   "metadata": {},
   "source": [
    "The maximum distance is 13925 ft. from the intersection. That's roughly 4.2km. That's too far to describe a point from an intersection. Having no guidance on a maximum threshold, we will leave the values as they are."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d4851e",
   "metadata": {},
   "source": [
    "## Column `direction`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "eec1ee15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "direction\n",
       "Not Stated    30964\n",
       "South          5388\n",
       "East           5173\n",
       "North          5074\n",
       "West           4930\n",
       "North Nor         2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['direction'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340995de",
   "metadata": {},
   "source": [
    "This column is a simple case. More than 50% of the rows do not have a direction from the intersection. We could potentially obtain it from the coordinates and the roads that form the intersection, but that would require bringing further data (the coordinates of the intersection) so we will not do it as part of this process. What we can do, is fix those two cases with value `North Nor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f0be18c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "direction\n",
       "Not Stated    30964\n",
       "South          5388\n",
       "East           5173\n",
       "North          5076\n",
       "West           4930\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['direction'] = df['direction'].str.replace('North Nor', 'North')\n",
    "df['direction'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337859be",
   "metadata": {},
   "source": [
    "Also, we should have no NULLs if we have the category `Not Stated`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f8cb28a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['direction'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efb6e03",
   "metadata": {},
   "source": [
    "## Columns `weather_1` and `weather_2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ac1ea170",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "weather_1\n",
       "Clear                       43366\n",
       "Cloudy                       4027\n",
       "Raining                      2871\n",
       "Not Stated                    791\n",
       "Other                         240\n",
       "Fog                           173\n",
       "Wind                           48\n",
       "Fog / Visibility: 10 ft         4\n",
       "Other: NOT AT SCENE             2\n",
       "Other: MISTING                  2\n",
       "Fog / Visibility: 800 ft        2\n",
       "Other: Unknown                  2\n",
       "Other: NOT ON SCENE             2\n",
       "Fog / Visibility                1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['weather_1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9fd11278",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "weather_2\n",
       "Not Stated                     50159\n",
       "Raining                          410\n",
       "Wind                             135\n",
       "Cloudy                           109\n",
       "Fog / Visibility                  16\n",
       "Other                             10\n",
       "Fog                                6\n",
       "Other: Drizzling                   4\n",
       "Other: MIST                        4\n",
       "Other: Night                       3\n",
       "Other: FALLING ASH                 3\n",
       "Other: SUNRISE                     2\n",
       "Other: Mist                        2\n",
       "Fog / Visibility: 500 ft           2\n",
       "Other: SUNSET                      2\n",
       "Other: smoke cloud                 2\n",
       "Other: Sunny                       2\n",
       "Fog / Visibility: 15 ft            2\n",
       "Snowing                            2\n",
       "Other: NOT ON SCENE                2\n",
       "Other: Sunset                      2\n",
       "Fog / Visibility: 30 ft            2\n",
       "Other: SMOKEY SKIES                2\n",
       "Other: HEAVY MIST                  2\n",
       "Fog / Visibility: 100 ft           2\n",
       "Other: SUN IN WB VIEW              2\n",
       "Other: Light drizzle (rain)        2\n",
       "Fog / Visibility: 10 ft            2\n",
       "Other: LIGHT MIST                  1\n",
       "Other: Misty                       1\n",
       "Other: SLIGHT MIST                 1\n",
       "Other: drizzle                     1\n",
       "Other: WET PAVEMENT                1\n",
       "Other: SMOKEY                      1\n",
       "Other: MISTING                     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['weather_2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "17daaf53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['weather_1'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "862708dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "631"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['weather_2'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1421b72",
   "metadata": {},
   "source": [
    "For some reason, a large variety of infrequent responses appear starting with `Other: ` and `Fog /`. We will consolidate those values in a single category. If the values were more frequent, it would be worth leaving them as they are, given that some contain addition small pieces of information.\n",
    "\n",
    "Also, it makes no sense to have a value being `Not Stated` and then having empty cells (NULL). We will tag all nulls as \"Not Stated\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9e55e30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['weather_1', 'weather_2']:\n",
    "    df.loc[df[column].isna(), column] = 'Not Stated'\n",
    "    df.loc[df[column].str.contains('Fog'), column] = 'Fog'\n",
    "    df.loc[df[column].str.contains('Other'), column] = 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "37b8cf78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "weather_1\n",
       "Clear         43366\n",
       "Cloudy         4027\n",
       "Raining        2871\n",
       "Not Stated      791\n",
       "Other           248\n",
       "Fog             180\n",
       "Wind             48\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['weather_1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9df3ea7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "weather_2\n",
       "Not Stated    50790\n",
       "Raining         410\n",
       "Wind            135\n",
       "Cloudy          109\n",
       "Other            53\n",
       "Fog              32\n",
       "Snowing           2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['weather_2'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b33ea11",
   "metadata": {},
   "source": [
    "## Column `collision_severity`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6798adac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "collision_severity\n",
       "Injury (Complaint of Pain)    33298\n",
       "Injury (Other Visible)        13687\n",
       "Injury (Severe)                4056\n",
       "Fatal                           485\n",
       "Medical                           5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['collision_severity'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb6670a",
   "metadata": {},
   "source": [
    "If we look at the SWITRS classification of the fields, we expect three levels of injury and fatal as categories. `Medical` does not fit any category, so we cannot reclassify it. We will leave it as it is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90628bbb",
   "metadata": {},
   "source": [
    "## Column `type_of_collision`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "78d9780d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type_of_collision\n",
       "Broadside             16124\n",
       "Vehicle/Pedestrian     9738\n",
       "Rear End               8622\n",
       "Sideswipe              7843\n",
       "Head-On                3346\n",
       "Other                  2266\n",
       "Not Stated             1636\n",
       "Hit Object             1226\n",
       "Overturned              730\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['type_of_collision'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "44c08561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['type_of_collision'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b684f87f",
   "metadata": {},
   "source": [
    "No strange values in the `type_of_collision` column, and there are no nulls, all values not entered are counted as `Not Stated`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4b91a5",
   "metadata": {},
   "source": [
    "## Column `mviw`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "99ddb3a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mviw\n",
       "Other Motor Vehicle               24673\n",
       "Pedestrian                        11329\n",
       "Bicycle                            6430\n",
       "Parked Motor Vehicle               3154\n",
       "Not Stated                         1617\n",
       "Fixed Object                       1371\n",
       "Other Object                       1087\n",
       "Motor Vehicle on Other Roadway      986\n",
       "Non-Collision                       750\n",
       "Train                               111\n",
       "Animal                               23\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['mviw'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ada1220c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['mviw'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c461417",
   "metadata": {},
   "source": [
    "No strange values in the `mviw` column, and there are no nulls. Nothing to do here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6429c60a",
   "metadata": {},
   "source": [
    "## Column `ped_action`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8ea26b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ped_action\n",
       "No Pedestrian Involved                       38884\n",
       "Crossing in Crosswalk at Intersection         6873\n",
       "Crossing Not in Crosswalk                     2170\n",
       "In Road, Including Shoulder                   1816\n",
       "Not Stated                                     799\n",
       "Not in Road                                    792\n",
       "Crossing in Crosswalk Not at Intersection      161\n",
       "Not In Road                                     28\n",
       "Approaching/Leaving School Bus                   8\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ped_action'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "892a1df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ped_action'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb978a7",
   "metadata": {},
   "source": [
    "Small issue here with two values being `Not in Road`, but one with capital \"I\". We will replace that one as it is used less frequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "50aca32e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ped_action\n",
       "No Pedestrian Involved                       38884\n",
       "Crossing in Crosswalk at Intersection         6873\n",
       "Crossing Not in Crosswalk                     2170\n",
       "In Road, Including Shoulder                   1816\n",
       "Not in Road                                    820\n",
       "Not Stated                                     799\n",
       "Crossing in Crosswalk Not at Intersection      161\n",
       "Approaching/Leaving School Bus                   8\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ped_action'] = df['ped_action'].str.replace('Not In Road', 'Not in Road')\n",
    "df['ped_action'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca497674",
   "metadata": {},
   "source": [
    "A different, more scalable approach to this issue, could be turning all values to lower case. If we know that upper case letters are not necessary to differentiate values (as it would in case we had acronyms), we can also use the `.title()`, `.upper()` or `.lower()` methods to format all the strings. While the number of different values won't change now that we have fixed the issue, we display here how it would have looked like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "46b78880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ped_action\n",
       "NO PEDESTRIAN INVOLVED                       38884\n",
       "CROSSING IN CROSSWALK AT INTERSECTION         6873\n",
       "CROSSING NOT IN CROSSWALK                     2170\n",
       "IN ROAD, INCLUDING SHOULDER                   1816\n",
       "NOT IN ROAD                                    820\n",
       "NOT STATED                                     799\n",
       "CROSSING IN CROSSWALK NOT AT INTERSECTION      161\n",
       "APPROACHING/LEAVING SCHOOL BUS                   8\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ped_action'].str.upper().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4d0df5b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ped_action\n",
       "No Pedestrian Involved                       38884\n",
       "Crossing In Crosswalk At Intersection         6873\n",
       "Crossing Not In Crosswalk                     2170\n",
       "In Road, Including Shoulder                   1816\n",
       "Not In Road                                    820\n",
       "Not Stated                                     799\n",
       "Crossing In Crosswalk Not At Intersection      161\n",
       "Approaching/Leaving School Bus                   8\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ped_action'].str.title().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e465b5",
   "metadata": {},
   "source": [
    "## Column `road_surface`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c4214975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "road_surface\n",
       "Dry             45202\n",
       "Wet              4952\n",
       "Not Stated       1292\n",
       "Slippery           55\n",
       "Snowy or Icy       30\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['road_surface'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ee7a76ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['road_surface'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231d7cc0",
   "metadata": {},
   "source": [
    "No issues with `road_surface`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90194e96",
   "metadata": {},
   "source": [
    "## Columns `road_cond_1` and `road_cond_2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f5798302",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "road_cond_1\n",
       "No Unusual Condition           48185\n",
       "Not Stated                      1855\n",
       "Construction or Repair Zone      541\n",
       "Other                            508\n",
       "Obstruction on Roadway           143\n",
       "Holes, Deep Rut                   99\n",
       "Holes, Deep Ruts                  77\n",
       "Loose Material on Roadway         67\n",
       "Reduced Roadway Width             47\n",
       "Flooded                            9\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['road_cond_1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7ab2cd7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "road_cond_2\n",
       "Not Stated                     51408\n",
       "No Unusual Condition              56\n",
       "Construction or Repair Zone       27\n",
       "Reduced Roadway Width             25\n",
       "Other                              7\n",
       "Obstruction on Roadway             7\n",
       "Loose Material on Roadway          1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['road_cond_2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6697f2ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['road_cond_1'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b0dd67ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['road_cond_2'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2c0c0a",
   "metadata": {},
   "source": [
    "There are two spellings of `Holes, Deep Ruts`, one with `s` and one without. We cannot use `.str.replace('Holes, Deep Rut', 'Holes, Deep Ruts')` because then the value with `s` will have two letter `s` at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6ebe824e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['road_cond_1'] == 'Holes, Deep Rut', 'road_cond_1'] = 'Holes, Deep Ruts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "19a296ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "road_cond_1\n",
       "No Unusual Condition           48185\n",
       "Not Stated                      1855\n",
       "Construction or Repair Zone      541\n",
       "Other                            508\n",
       "Holes, Deep Ruts                 176\n",
       "Obstruction on Roadway           143\n",
       "Loose Material on Roadway         67\n",
       "Reduced Roadway Width             47\n",
       "Flooded                            9\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['road_cond_1'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50f939d",
   "metadata": {},
   "source": [
    "## Column `lighting`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7a3306ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lighting\n",
       "Daylight                                32713\n",
       "Dark - Street Lights                    15815\n",
       "Dusk - Dawn                              1866\n",
       "Not Stated                                647\n",
       "Dark - No Street Lights                   388\n",
       "Dark - Street Lights Not Functioning      102\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lighting'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ebdccfe5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lighting'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4320287",
   "metadata": {},
   "source": [
    "No issues with column `lighting`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c23ff9",
   "metadata": {},
   "source": [
    "## Column `control_device`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "10da2fc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "control_device\n",
       "Functioning        32701\n",
       "Not Stated          1298\n",
       "Not Functioning      196\n",
       "Obscured              44\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['control_device'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "258d82a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17292"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['control_device'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ef4710",
   "metadata": {},
   "source": [
    "We need to fix the issue of having `Not Stated` values in the column `control_device` while having nulls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9a66bc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['control_device'].isna(), 'control_device'] = 'Not Stated'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2014f690",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18590"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['control_device'].value_counts().loc['Not Stated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3c798e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['control_device'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd77e6f",
   "metadata": {},
   "source": [
    "## Column `vz_pcf_description`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f4d99b8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vz_pcf_description\n",
       "Unsafe speed for prevailing conditions                               8902\n",
       "Red signal - driver or bicyclist responsibilities                    5066\n",
       "Driver or bicyclist to yield right-of-way at crosswalks              5063\n",
       "Unsafe turn or lane change prohibited                                4378\n",
       "Unknown                                                              3160\n",
       "                                                                     ... \n",
       "Dumping material on highway or right-of-way prohibited                  2\n",
       "Refusal to present license to officer                                   1\n",
       "Headsets, ear plugs, or earphones in or over both ears prohibited       1\n",
       "Motorized scooter operation requirements                                1\n",
       "Blind pedestrians right-of-way                                          1\n",
       "Name: count, Length: 181, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['vz_pcf_description'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "63222d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['vz_pcf_description'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b31a40",
   "metadata": {},
   "source": [
    "We observe the value `Unknown`, when we used to have `Not Stated` when the officer didn't select any category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "998f376c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['vz_pcf_description'].value_counts().loc['Not Stated']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2908d7bc",
   "metadata": {},
   "source": [
    "There are a few `Not Stated` too. We will convert all to that value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a7546913",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['vz_pcf_description'] == 'Unknown', 'vz_pcf_description'] = 'Not Stated'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f87373e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3207"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['vz_pcf_description'].value_counts().loc['Not Stated']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb91428",
   "metadata": {},
   "source": [
    "Also, this column has more values than are shown by default, and they are descriptions. We will use again the similarity search to consolidate some categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4a1d02f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Red signal - driver or bicyclist responsibilities', 'Green signal - driver or bicyclist responsibilities']\n",
      "['Red signal - driver or bicyclist responsibilities', 'Red signal - driver or bicyclist responsibilities with right turn']\n",
      "['Red signal - pedestrian responsibilities', 'Green signal - pedestrian responsibilities']\n",
      "['Failure to yield to emergency vehicle', 'Failure to yield to emergency vehicle - pedestrian']\n",
      "['Actions required at flashing red signal', 'Actions required at flashing yellow signal']\n",
      "['Operating a non-motorized user-propelled vehicle in a reckless manner', 'Local ordinance, operating a non-motorized user-propelled vehicle in a reckless manner']\n",
      "['Local ordinance, riding a non-motorized user-propelled vehicle in the roadway', 'Riding a non-motorized user-propelled vehicle in the roadway']\n"
     ]
    }
   ],
   "source": [
    "df_study = df['vz_pcf_description'].drop_duplicates()\n",
    "for i in range(len(df_study)):\n",
    "    for j in range(i+1, len(df_study)):\n",
    "        ratio = difflib.SequenceMatcher(None, df_study.iloc[i], df_study.iloc[j]).ratio()\n",
    "        if ratio > 0.85 and ratio < 1:\n",
    "            print([df_study.iloc[i], df_study.iloc[j]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07553d62",
   "metadata": {},
   "source": [
    "We observe two type of differences in the values:\n",
    "1. Those that the values are similar, but there is a difference in the situation (like the color of a light).\n",
    "2. Those that have the same description, but are violations of different laws (local vs state, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "81b89875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local ordinance, bicycles prohibited from sidewalk\n",
      "Local ordinance, driving in transit-only area\n",
      "Local ordinance, non-motorized user-propelled vehicle - unspecified violation\n",
      "Local ordinance, operating a non-motorized user-propelled vehicle in a reckless manner\n",
      "Local ordinance, pedestrian crossing at an inappropriate location\n",
      "Local ordinance, riding a non-motorized user-propelled vehicle in the roadway\n",
      "Local ordinance, riding non-motorized user-propelled vehicles in a business district within the City\n",
      "Local ordinance, sleeping on sidewalk prohibited\n"
     ]
    }
   ],
   "source": [
    "for e in df_study[df_study.str.contains(\"ordinance\")].sort_values():\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438c83d8",
   "metadata": {},
   "source": [
    "Give than this fact could be relevant for the analysis, we keep the data as it is. If the user analysing the data wants to consider the primary collision factor the same regardless of the ordinance, they can still group values. Remember we removed three columns that expanded on this descriptions. We could recover them in case we want to dive deeper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d96df3",
   "metadata": {},
   "source": [
    "## Column `dph_col_grp_description`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e7f0e8e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dph_col_grp_description\n",
       "Vehicle(s) Only Involved                    27024\n",
       "Vehicle-Pedestrian                          10538\n",
       "Vehicle-Bicycle                              5748\n",
       "AA                                           4593\n",
       "BB                                           1567\n",
       "CC                                            786\n",
       "Bicycle Only                                  482\n",
       "Bicycle-Pedestrian                            360\n",
       "Bicycle-Parked Car                            215\n",
       "FF                                             73\n",
       "DD                                             47\n",
       "EE                                             24\n",
       "Vehicle-Bicycle-Pedestrian                     24\n",
       "Pedestrian Only or Pedestrian-Parked Car       24\n",
       "Bicycle-Unknown/Not Stated                      6\n",
       "BB CC                                           6\n",
       "Unknown/Not Stated                              5\n",
       "GG                                              3\n",
       "II                                              2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dph_col_grp_description'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8bbee708",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dph_col_grp_description'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbba461e",
   "metadata": {},
   "source": [
    "It's not clear what the values `AA`, `BB`, etc. are. Most likely, internal codes that do not appear in the two sources we have for descriptions. We will only fix the `Not Stated` cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "45a1600e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['dph_col_grp_description'].isna(), 'dph_col_grp_description'] = 'Not Stated'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f769c64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['dph_col_grp_description'] == 'Unknown/Not Stated', 'dph_col_grp_description'] = 'Not Stated'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "031b4692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dph_col_grp_description'].value_counts().loc['Not Stated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "073ad95c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dph_col_grp_description'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec626c1",
   "metadata": {},
   "source": [
    "## Column `party_number_ckey`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "75e43d68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "party_number_ckey\n",
       "1     24563\n",
       "2     22637\n",
       "3      3026\n",
       "4       804\n",
       "5       292\n",
       "6       110\n",
       "7        47\n",
       "8        21\n",
       "9        14\n",
       "10       10\n",
       "11        3\n",
       "12        1\n",
       "13        1\n",
       "14        1\n",
       "15        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['party_number_ckey'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d92f8d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['party_number_ckey'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef43e837",
   "metadata": {},
   "source": [
    "No issues, but an observation: there is an accident with 15 parties involved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b66e11",
   "metadata": {},
   "source": [
    "## Column `party_number_ckey`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3b48d0cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "party_type\n",
       "Driver            36909\n",
       "Pedestrian         6248\n",
       "Bicyclist          4091\n",
       "Parked Vehicle     3147\n",
       "Other              1136\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['party_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "48f46923",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['party_type'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e1142f",
   "metadata": {},
   "source": [
    "No data issues here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c2c5bc",
   "metadata": {},
   "source": [
    "## Column `at_fault`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "618f439a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "at_fault\n",
       "No     29879\n",
       "Yes    21652\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['at_fault'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a3d193e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['at_fault'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f313bf57",
   "metadata": {},
   "source": [
    "No data issues here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a774afb5",
   "metadata": {},
   "source": [
    "## Column `party_sex`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "02e8f1b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "party_sex\n",
       "Male          31601\n",
       "Female        14450\n",
       "Not Stated     4710\n",
       "Other           770\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['party_sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "11099edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['party_sex'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6fe4b5",
   "metadata": {},
   "source": [
    "No data issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e6d2be",
   "metadata": {},
   "source": [
    "## Column `party_age`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d3cde0aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "party_age\n",
       " 28.0     1219\n",
       " 30.0     1205\n",
       " 27.0     1173\n",
       " 32.0     1172\n",
       " 25.0     1161\n",
       "          ... \n",
       "-961.0       1\n",
       " 97.0        1\n",
       " 108.0       1\n",
       "-941.0       1\n",
       "-951.0       1\n",
       "Name: count, Length: 115, dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['party_age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f4687eec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7975"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['party_age'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd75a61",
   "metadata": {},
   "source": [
    "Several data issues here. We observe already some values of `party_age` that are negative. That is not possible, so we will remove those values. Since the column is an integer, we cannot have the value `Not Stated`, so those values will add to the nulls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3263854d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['party_age'] < 0, 'party_age'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e659d36",
   "metadata": {},
   "source": [
    "Also, we should convert the age to integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "861bdc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['party_age'] = df['party_age'].astype(pd.Int64Dtype())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7b3a2623",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      43519.0\n",
       "mean     41.623429\n",
       "std      16.292647\n",
       "min            0.0\n",
       "25%           29.0\n",
       "50%           39.0\n",
       "75%           53.0\n",
       "max          109.0\n",
       "Name: party_age, dtype: Float64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['party_age'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4634b3d5",
   "metadata": {},
   "source": [
    "The values shown in describe are always `float`. It is interesting to see that the age values range from 0 to 109. Remember that this are parties involved, so it could be pedestrians, passengers, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5c1e5e",
   "metadata": {},
   "source": [
    "## Column `party_sobriety`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "55c8e994",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "party_sobriety\n",
       "Had Not Been Drinking                     36010\n",
       "Not Stated                                 7503\n",
       "Impairment Not Known                       5201\n",
       "Had Been Drinking, Not Under Influence     1143\n",
       "Had Been Drinking, Under Influence          869\n",
       "Had Been Drinking, Impairment Unknown       698\n",
       "Not Applicable                               92\n",
       "Sleepy/Fatigued                               8\n",
       "Under Drug Influence                          3\n",
       "Impairment Unknown                            2\n",
       "Impairment - Physical                         2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['party_sobriety'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c759e210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['party_sobriety'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2e94d0",
   "metadata": {},
   "source": [
    "There are a few values to discuss. There are several combinations of drinking and impairements, all having different meanings, so we will keep them. The value `Not Applicable` is not the same as `Not Stated`, it means the column makes no sense (for example, a parked car with no people). Finally, two values have the same meaning with different wording, we will group them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e2fc074d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['party_sobriety'] == 'Impairment Unknown', 'party_sobriety'] = 'Impairment Not Known'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0ca75874",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "party_sobriety\n",
       "Had Not Been Drinking                     36010\n",
       "Not Stated                                 7503\n",
       "Impairment Not Known                       5203\n",
       "Had Been Drinking, Not Under Influence     1143\n",
       "Had Been Drinking, Under Influence          869\n",
       "Had Been Drinking, Impairment Unknown       698\n",
       "Not Applicable                               92\n",
       "Sleepy/Fatigued                               8\n",
       "Under Drug Influence                          3\n",
       "Impairment - Physical                         2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['party_sobriety'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e7afe5bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "party_sex\n",
       "Not Stated    67\n",
       "Male          18\n",
       "Female         7\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['party_sobriety'] == 'Not Applicable']['party_sex'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9e5dbe",
   "metadata": {},
   "source": [
    "## Column `party_drug_physical`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "940ab4a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "party_drug_physical\n",
       "Not Stated                48142\n",
       "Not Applicable             3028\n",
       "Under Drug Influence        111\n",
       "Impairment Not Known         92\n",
       "Sleepy/Fatigued              87\n",
       "Impairment - Physical        37\n",
       "Suspected Cannabis Use       30\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['party_drug_physical'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0df456b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['party_drug_physical'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b44466",
   "metadata": {},
   "source": [
    "No data issues here. Given the low quantity of results with values, we will drop this column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0a4f6e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='party_drug_physical', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f82b78d",
   "metadata": {},
   "source": [
    "## Column `dir_of_travel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2a22bcae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dir_of_travel\n",
       "East          12507\n",
       "South         12409\n",
       "North         12292\n",
       "West          11532\n",
       "Not Stated     2791\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dir_of_travel'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e40a341f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dir_of_travel'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b682b9",
   "metadata": {},
   "source": [
    "No issues here either."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cea393e",
   "metadata": {},
   "source": [
    "## Columns  `party_safety_equip_1` and `party_safety_equip_2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "765718c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "party_safety_equip_1\n",
       "Air Bag Deployed                  5069\n",
       "Air Bag Not Deployed             14653\n",
       "Lap Belt Not Used                   28\n",
       "Lap Belt Used                      628\n",
       "Lap/Shoulder Harness Not Used      155\n",
       "Lap/Shoulder Harness Used         7583\n",
       "M/C Helmet Driver - No             263\n",
       "M/C Helmet Driver - Yes            996\n",
       "M/C Helmet Passenger - No            3\n",
       "M/C Helmet Passenger - Yes           6\n",
       "None In Vehicle                    277\n",
       "Not Required                      6268\n",
       "Not Stated                       12983\n",
       "Other                              206\n",
       "Passive Restraint Not Used           1\n",
       "Passive Restraint Used               6\n",
       "Shoulder Harness Not Used           27\n",
       "Shoulder Harness Used              257\n",
       "Unknown                           2121\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['party_safety_equip_1'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1f7d2742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "party_safety_equip_2\n",
       "Air Bag Deployed                         167\n",
       "Air Bag Not Deployed                     459\n",
       "Child Restraint in Vehicle Not Used        1\n",
       "Child Restraint in Vehicle Used            3\n",
       "Lap Belt Not Used                         72\n",
       "Lap Belt Used                           1304\n",
       "Lap/Shoulder Harness Not Used            392\n",
       "Lap/Shoulder Harness Used              15999\n",
       "M/C Helmet Driver - No                   767\n",
       "M/C Helmet Driver - Yes                 2004\n",
       "M/C Helmet Passenger - No                 16\n",
       "M/C Helmet Passenger - Yes                22\n",
       "No Child Restraint in Vehicle              1\n",
       "None In Vehicle                         1252\n",
       "None Stated                                1\n",
       "Not Required                             544\n",
       "Not Stated                             25481\n",
       "Other                                      7\n",
       "Passive Restraint Used                     8\n",
       "Shoulder Harness Not Used                 44\n",
       "Shoulder Harness Used                    527\n",
       "Unknown                                 2456\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['party_safety_equip_2'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "526a743d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['party_safety_equip_1'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01208aa",
   "metadata": {},
   "source": [
    "We see a differentiation made sometimes between lap and shoulder belts. It is unclear whether Lap/Shoulder means either or both. If it would mean either, we could merge several values together; if it would mean both it would make sense to keep them separated for analysis. We don't know, thus we will keep it separated.\n",
    "\n",
    "As we have done before, we will replace nulls and `Unknown`/ `None Stated` values with `Not Stated`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f73d5d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['party_safety_equip_1', 'party_safety_equip_2']:\n",
    "    df.loc[df[column].isna(), column] = 'Not Stated'\n",
    "    df.loc[df[column].isin(['Unknown', 'None Stated']), column] = 'Not Stated'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d438528b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "party_safety_equip_1\n",
       "Air Bag Deployed                  5069\n",
       "Air Bag Not Deployed             14653\n",
       "Lap Belt Not Used                   28\n",
       "Lap Belt Used                      628\n",
       "Lap/Shoulder Harness Not Used      155\n",
       "Lap/Shoulder Harness Used         7583\n",
       "M/C Helmet Driver - No             263\n",
       "M/C Helmet Driver - Yes            996\n",
       "M/C Helmet Passenger - No            3\n",
       "M/C Helmet Passenger - Yes           6\n",
       "None In Vehicle                    277\n",
       "Not Required                      6268\n",
       "Not Stated                       15105\n",
       "Other                              206\n",
       "Passive Restraint Not Used           1\n",
       "Passive Restraint Used               6\n",
       "Shoulder Harness Not Used           27\n",
       "Shoulder Harness Used              257\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['party_safety_equip_1'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "28ce7f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "party_safety_equip_2\n",
       "Air Bag Deployed                         167\n",
       "Air Bag Not Deployed                     459\n",
       "Child Restraint in Vehicle Not Used        1\n",
       "Child Restraint in Vehicle Used            3\n",
       "Lap Belt Not Used                         72\n",
       "Lap Belt Used                           1304\n",
       "Lap/Shoulder Harness Not Used            392\n",
       "Lap/Shoulder Harness Used              15999\n",
       "M/C Helmet Driver - No                   767\n",
       "M/C Helmet Driver - Yes                 2004\n",
       "M/C Helmet Passenger - No                 16\n",
       "M/C Helmet Passenger - Yes                22\n",
       "No Child Restraint in Vehicle              1\n",
       "None In Vehicle                         1252\n",
       "Not Required                             544\n",
       "Not Stated                             27942\n",
       "Other                                      7\n",
       "Passive Restraint Used                     8\n",
       "Shoulder Harness Not Used                 44\n",
       "Shoulder Harness Used                    527\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['party_safety_equip_2'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c619e71",
   "metadata": {},
   "source": [
    "## Column `finan_respons`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c753c985",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "finan_respons\n",
       "Yes Proof of Insurance Obtained    29135\n",
       "Not Applicable                     11389\n",
       "Not Stated                          9417\n",
       "No Proof of Insurance Obtained      1463\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['finan_respons'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c7d9bb73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['finan_respons'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc1caa9",
   "metadata": {},
   "source": [
    "Only need to fix the nulls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "10d3b86d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['finan_respons'].isna(), 'finan_respons'] = 'Not Stated'\n",
    "df['finan_respons'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175bf3ad",
   "metadata": {},
   "source": [
    "## Columns `sp_info_1` , `sp_info_2`, and `sp_info_3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f331947d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sp_info_1\n",
       "Cell Phone Not In Use                                      27817\n",
       "Not Stated                                                 22254\n",
       "Other                                                        591\n",
       "Cell Phone Handheld In Use                                   278\n",
       "Cell Phone Handsfree In Use                                  257\n",
       "Vehicle for Hire (Taxi, Uber, Lyft, etc) WITH Passenger      158\n",
       "Vehicle for Hire (Taxi, Uber, Lyft, etc) NO Passenger         65\n",
       "Hazardous Material                                            36\n",
       "No Cell Phone/Unknown                                         36\n",
       "32 Ft Trailer Combo                                           18\n",
       "School Bus Related                                            15\n",
       "75 Ft Motortruck Combo                                         6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sp_info_1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "9110f1f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sp_info_2\n",
       "Not Stated                                                 39378\n",
       "Cell Phone Not In Use                                      11504\n",
       "Vehicle for Hire (Taxi, Uber, Lyft, etc) WITH Passenger      278\n",
       "Vehicle for Hire (Taxi, Uber, Lyft, etc) NO Passenger        127\n",
       "Cell Phone Handheld In Use                                    94\n",
       "Cell Phone Handsfree In Use                                   76\n",
       "Hazardous Material                                            18\n",
       "32 Ft Trailer Combo                                           12\n",
       "School Bus Related                                            11\n",
       "TNC (Uber, Lyft, etc) WITH Passenger                          11\n",
       "Other                                                         10\n",
       "TNC (Uber, Lyft, etc) NO Passenger                             6\n",
       "75 Ft Motortruck Combo                                         6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sp_info_2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7b5aa1f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sp_info_3\n",
       "Not Stated    51529\n",
       "Other             2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sp_info_3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d576f9f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sp_info_1'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e5d26dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sp_info_2'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "8f77a6fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sp_info_3'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e92623",
   "metadata": {},
   "source": [
    "The special info categories do not contain mutually exclusive values, and those found cannot be further grouped. `sp_info_3` has no useful values. `sp_info_1` and `sp_info_2` are a mix of unrelated things like cell usage or whether hazardous materials were involved. The most frequent value in `sp_info_1` is `Cell Phone Not In Use` and the rest are mostly `Not Stated` or some values that could also be cell used or not. Thus, there is limited value in those columns too. We will drop all 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b79e65c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['sp_info_1', 'sp_info_2', 'sp_info_3']\n",
    "df.drop(columns=drop_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9f0950",
   "metadata": {},
   "source": [
    "## `oaf` columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "fc01c2db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "oaf_viol_cat\n",
       "Not Stated                     24956\n",
       "Hit and Run                        3\n",
       "Failure to Heed Stop Signal        2\n",
       "Unsafe Speed                       2\n",
       "Automobile Right-of-Way            1\n",
       "Other Non-Moving Violation         1\n",
       "Wrong Side of Road                 1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['oaf_viol_cat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "bac4c89b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "oaf_viol_section\n",
       "Not Stated     7280\n",
       "22350           673\n",
       "20001(a)        591\n",
       "12500(a)        173\n",
       "20001           170\n",
       "               ... \n",
       "22107(a)          1\n",
       "20001vc           1\n",
       "21293(a)          1\n",
       "22100 cvc         1\n",
       "21453(a) vc       1\n",
       "Name: count, Length: 513, dtype: int64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['oaf_viol_section'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "51e1e08d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "oaf_violation_code\n",
       "Not Stated    45570\n",
       "Vehicle        4147\n",
       "20001(a)         10\n",
       "20002             2\n",
       "20002(a)          2\n",
       "22350             2\n",
       "21460             1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['oaf_violation_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "be4889a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "oaf_violation_suffix\n",
       "Not Stated    8206\n",
       "A                6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['oaf_violation_suffix'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "3f540a42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "oaf_1\n",
       "None Apparent                  33842\n",
       "Not Stated                      8235\n",
       "Violation                       5686\n",
       "Stop and Go Traffic              925\n",
       "Inattention                      751\n",
       "Other                            691\n",
       "Vision Obscurements              590\n",
       "Unfamiliar With Road             243\n",
       "Entering - Leaving Ramp          149\n",
       "Uninvolved Vehicle               136\n",
       "Runaway Vehicle                  107\n",
       "Previous Collision                92\n",
       "Defective Vehicle Equipment       73\n",
       "Vision Obscurement                11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['oaf_1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b4949649",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "oaf_2\n",
       "Not Stated                     48001\n",
       "None Apparent                   1318\n",
       "Other                            124\n",
       "Stop and Go Traffic              101\n",
       "Inattention                       75\n",
       "Runaway Vehicle                   34\n",
       "Vision Obscurements               28\n",
       "Unfamiliar With Road              26\n",
       "Entering - Leaving Ramp           22\n",
       "Defective Vehicle Equipment       15\n",
       "Uninvolved Vehicle                13\n",
       "Previous Collision                11\n",
       "Violation                         11\n",
       "Vision Obscurement                 2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['oaf_2'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d686a57",
   "metadata": {},
   "source": [
    "There are three columns that have hardly any information, most values are `Not Stated`: `oaf_viol_cat`, `oaf_violation_code`, and `oaf_violation_suffix`. We will start dropping them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "2dfce5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['oaf_viol_cat', 'oaf_violation_code', 'oaf_violation_suffix']\n",
    "df.drop(columns=drop_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d688ba0",
   "metadata": {},
   "source": [
    "We will also drop the other columns. While `oaf_viol_section` contains several values, the data does not contain the meaning of the values. The descriptions in `oaf_1` and `oaf_2` should make it easier to read but most are missing. Hence, for the analysis we will drop all remaining \"oaf\" columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e9d01b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['oaf_viol_section', 'oaf_1', 'oaf_2']\n",
    "df.drop(columns=drop_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4daca7e",
   "metadata": {},
   "source": [
    "## Column `party_number_killed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "cab65dac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "party_number_killed\n",
       "0    51313\n",
       "1      216\n",
       "2        2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['party_number_killed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a0b4211b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['party_number_killed'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53fff36",
   "metadata": {},
   "source": [
    "All good here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b10ed4a",
   "metadata": {},
   "source": [
    "## Column `party_number_injured`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "49f8a233",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "party_number_injured\n",
       "1     24711\n",
       "0     24253\n",
       "2      2047\n",
       "3       381\n",
       "4        92\n",
       "5        33\n",
       "6         8\n",
       "7         4\n",
       "9         1\n",
       "13        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['party_number_injured'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "3dc0cbdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['party_number_injured'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7923b88b",
   "metadata": {},
   "source": [
    "All good here too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7213b839",
   "metadata": {},
   "source": [
    "## Column `move_pre_acc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "8ce5c20c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "move_pre_acc\n",
       "Proceeding Straight                       27744\n",
       "Making Left Turn                           5403\n",
       "Stopped                                    4306\n",
       "Not Stated                                 2743\n",
       "Parked                                     2605\n",
       "Making Right Turn                          2194\n",
       "Other                                      1559\n",
       "Changing Lanes                              968\n",
       "Entering Traffic                            834\n",
       "Slowing/Stopping                            672\n",
       "Backing                                     628\n",
       "Making U Turn                               580\n",
       "Passing Other Vehicle                       250\n",
       "Traveling Wrong Way                         238\n",
       "Parking Maneuver                            224\n",
       "Ran Off Road                                196\n",
       "Other Unsafe Turning                        124\n",
       "Merging                                     121\n",
       "Crossed Into Opposing Lane                  100\n",
       "Crossed Into Opposing Lane - Unplanned       40\n",
       "Crossing Into Opposing Lane                   1\n",
       "Stopped In Road                               1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['move_pre_acc'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "7adf37ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['move_pre_acc'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a2f256",
   "metadata": {},
   "source": [
    "Those cases with just one occurrence can be changed to same categories with slightly different wording:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "37262b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['move_pre_acc'] == 'Stopped In Road', 'move_pre_acc'] = 'Stopped'\n",
    "df.loc[df['move_pre_acc'] == 'Crossing Into Opposing Lane', 'move_pre_acc'] = 'Crossed Into Opposing Lane'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "93939881",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "move_pre_acc\n",
       "Proceeding Straight                       27744\n",
       "Making Left Turn                           5403\n",
       "Stopped                                    4307\n",
       "Not Stated                                 2743\n",
       "Parked                                     2605\n",
       "Making Right Turn                          2194\n",
       "Other                                      1559\n",
       "Changing Lanes                              968\n",
       "Entering Traffic                            834\n",
       "Slowing/Stopping                            672\n",
       "Backing                                     628\n",
       "Making U Turn                               580\n",
       "Passing Other Vehicle                       250\n",
       "Traveling Wrong Way                         238\n",
       "Parking Maneuver                            224\n",
       "Ran Off Road                                196\n",
       "Other Unsafe Turning                        124\n",
       "Merging                                     121\n",
       "Crossed Into Opposing Lane                  101\n",
       "Crossed Into Opposing Lane - Unplanned       40\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['move_pre_acc'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b7ef38",
   "metadata": {},
   "source": [
    "## Column `vehicle_year`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "86d1e622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vehicle_year\n",
       "2016.0    2955\n",
       "2015.0    2887\n",
       "2017.0    2443\n",
       "2013.0    2277\n",
       "2014.0    2151\n",
       "          ... \n",
       "1958.0       1\n",
       "208.0        1\n",
       "1916.0       1\n",
       "66.0         1\n",
       "1893.0       1\n",
       "Name: count, Length: 128, dtype: int64"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['vehicle_year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f934bead",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    37487.000000\n",
       "mean      2000.957265\n",
       "std        139.714552\n",
       "min          0.000000\n",
       "25%       2006.000000\n",
       "50%       2013.000000\n",
       "75%       2016.000000\n",
       "max       5015.000000\n",
       "Name: vehicle_year, dtype: float64"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['vehicle_year'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "c6559d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(df['vehicle_year'].isna().sum() / df.shape[0], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62d0794",
   "metadata": {},
   "source": [
    "Vehicle year clearly has some issues.\n",
    "- Decimals used when it should be an integer.\n",
    "- Year as low as 0 (cars were not invented yet!)\n",
    "- Year as high as 5015 (a Delorian, perhaps? McFly, is that you?)\n",
    "- 27% of the rows are missing the values (nothing we can do about it here)\n",
    "\n",
    "Let's tackle first the data type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "88e0b1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vehicle_year'] = df['vehicle_year'].astype(pd.Int64Dtype())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d318367",
   "metadata": {},
   "source": [
    "How many cars have the wrong values?\n",
    "- Built in the future\n",
    "- Built too far in the past (we will be \"generous\" and assume any car built before year 1900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "7fc5d949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "355"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_future = ((df['collision_datetime'].dt.year-df['vehicle_year']) < 0)\n",
    "f_too_old = (df['vehicle_year'] < 1900)\n",
    "(f_future | f_too_old).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac0ec97",
   "metadata": {},
   "source": [
    "Rules we will use to convert the numbers:\n",
    "- If the year is between 2023 and 1900 (both included), we do not change the year.\n",
    "- Otherwise, if the year is between 100 and 199 (1XX), we assume that the intention was to write 19XX.\n",
    "- Otherwise, if the year's last two numbers are between 0 and 24 (XX), we assume it was year 20XX.\n",
    "- Otherwise, if the year's last two numbers are between 25 and 99 (XX), we assume it was year 19XX.\n",
    "\n",
    "- After the previous changes, any year after the `collision_datetime` year, we assume it was a brand new car.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "fede55a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = df['vehicle_year']%100\n",
    "collision_year = df['collision_datetime'].dt.year\n",
    "\n",
    "# If case\n",
    "mask_excluded = (df['vehicle_year'] >= 2024) | (df['vehicle_year'] < 1900)\n",
    "\n",
    "# \"otherwise\" 1\n",
    "f1 = mask_excluded & (df['vehicle_year'] >= 100) & (df['vehicle_year'] <= 199)\n",
    "df.loc[df[f1].index, 'vehicle_year'] = xx + 1900    \n",
    "\n",
    "# \"otherwise\" 2\n",
    "f2 = mask_excluded & (~f1) & (xx < 24)\n",
    "df.loc[df[f2].index, 'vehicle_year'] = xx + 2000   \n",
    "\n",
    "# \"otherwise\" 3\n",
    "f3 = mask_excluded & (~f1) & (xx >= 24)\n",
    "df.loc[df[f3].index, 'vehicle_year'] = xx + 1900   \n",
    "\n",
    "f = collision_year < df['vehicle_year']\n",
    "df.loc[df[f].index, 'vehicle_year'] = collision_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "3592f085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_future = ((df['collision_datetime'].dt.year-df['vehicle_year']) < 0)\n",
    "f_too_old = (df['vehicle_year'] < 1900)\n",
    "(f_future | f_too_old).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333cea47",
   "metadata": {},
   "source": [
    "## Column `vehicle_make`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "1e091ea4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vehicle_make\n",
       "TOYOTA                    2627\n",
       "HONDA                     1623\n",
       "FORD                      1227\n",
       "NISSAN                     667\n",
       "CHEVROLET                  495\n",
       "                          ... \n",
       "WTIN/UNK/WHITE               1\n",
       "CHEV/CORVETTE/YLW            1\n",
       "Toyota / Prius /Orange       1\n",
       "Lexus/GS300/Gold             1\n",
       "Hyundia/silver               1\n",
       "Name: count, Length: 20766, dtype: int64"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['vehicle_make'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "42f1baf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7775"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['vehicle_make'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "8ae8cd4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vehicle_make\n",
       "TOYOTA                   2627\n",
       "HONDA                    1623\n",
       "FORD                     1227\n",
       "NISSAN                    667\n",
       "CHEVROLET                 495\n",
       "BMW                       448\n",
       "HYUNDAI                   346\n",
       "LEXUS                     334\n",
       "MERCEDES-BENZ             321\n",
       "VOLKSWAGEN                290\n",
       "DODGE                     270\n",
       "UNKNOWN                   261\n",
       "ACURA                     222\n",
       "MAZDA                     196\n",
       "SUBARU                    171\n",
       "JEEP                      171\n",
       "AUDI                      151\n",
       "KIA                       131\n",
       "GMC                       128\n",
       "CHRYSLER                  114\n",
       "BICYCLE                   113\n",
       "TOYT                      112\n",
       "YAMAHA                    105\n",
       "VOLVO                     102\n",
       "INFINITI                   94\n",
       "Unknown                    86\n",
       "MINI                       82\n",
       "KAWASAKI                   76\n",
       "Toyota/Prius/White         76\n",
       "SUZUKI                     71\n",
       "VESPA                      70\n",
       "HARLEY-DAVIDSON            68\n",
       "MITSUBISHI                 66\n",
       "Honda/Civic/Black          65\n",
       "Toyota/Prius/Silver        65\n",
       "TOYOTA/PRIUS/WHITE         60\n",
       "CADILLAC                   60\n",
       "Toyota/Corolla/Silver      60\n",
       "NEW FLYER                  59\n",
       "HONDA/CIVIC/SILVER         56\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['vehicle_make'].value_counts().iloc[0:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddfc962",
   "metadata": {},
   "source": [
    "As we can observe, the most frequent values are the overall brand names, and then, a combination of brand, model and even color. We will leave only the brand, as otherwise there are too many different values, and the majority only have the brand. Before anything else, we will convert all text to upper case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "baf613db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vehicle_make'] = df['vehicle_make'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "d3e27560",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['vehicle_make'] == 'NOT STATED', 'vehicle_make'] = 'UNKNOWN'\n",
    "df.loc[df['vehicle_make'].isna(), 'vehicle_make'] = 'UNKNOWN'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cce7bd",
   "metadata": {},
   "source": [
    "Let's create a dataframe with those values that have no special characters, and consider those to be the brands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "209e6927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "573"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = df['vehicle_make'].str.match(r'^[A-Z]+$') # Strings without special characters\n",
    "mask = mask & (~(df['vehicle_make'] == 'UNKNOWN')) # do not consider UNKNOWN as a brand\n",
    "vehicle_brands = df[mask]['vehicle_make'].value_counts().index # Unique values\n",
    "vehicle_brands.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a3081d",
   "metadata": {},
   "source": [
    "Next, we try to find for each value that is not identified as a brand, if it contains one of the brands (prioritizing those with higher frequency). This has some issues. For example, `GRAY` has been identified as one of the most common brands (many officers simply write the color) and thus, any brand that has appeared less frequently than the word gray, will be misidentified as brand `GRAY`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "84bb0dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "for brand in vehicle_brands:\n",
    "    pattern = r'(?<![A-Z])' + re.escape(brand) + r'(?![A-Z])'\n",
    "    mask_unbranded = ~df['vehicle_make'].isin(vehicle_brands)\n",
    "    mask_replace = mask_unbranded & df['vehicle_make'].str.contains(pattern, regex=True) \n",
    "    df.loc[mask_replace, 'vehicle_make'] = brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "8b370cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vehicle_make\n",
       "UNKNOWN               8133\n",
       "TOYOTA                7246\n",
       "HONDA                 5021\n",
       "FORD                  3542\n",
       "NISSAN                1931\n",
       "                      ... \n",
       "MUNIBUS                  1\n",
       "WIDEWHEEL  MERCANE       1\n",
       "MERZU                    1\n",
       "HINDA                    1\n",
       "ALLWAY YA309C/D          1\n",
       "Name: count, Length: 943, dtype: int64"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['vehicle_make'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "fde6c025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "943"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['vehicle_make'].value_counts().shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2dbb65",
   "metadata": {},
   "source": [
    "Next we replace values with similar ones, progressively to approach the most frequent appearing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "a157bcb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9] GILLI new: GILLIG\n",
      "[0.9] GENZIE new: GENZE\n",
      "[0.9] SPECIALLIZED new: SPECIALIZED\n",
      "[0.9] FORK LIFT new: FORKLIFT\n",
      "[0.9] NINE BOT new: NINEBOT\n",
      "[0.9] PETERBUILT new: PETERBILT\n",
      "[0.9] NISSA new: NISSAN\n",
      "[0.9] KALKHOFF new: KAL KHOFF\n",
      "[0.9] XTRACYLE new: XTRACYCLE\n",
      "[0.9] BICYLCE new: BICYLE\n",
      "[0.9] PINARELO new: PINARELLO\n",
      "[0.9] CANNON DALE new: CANNONDALE\n",
      "[0.9] HON/CIV/SIL new: HON/CRV/SIL\n",
      "[0.9] CHEVEROLET new: CHEVROLET\n",
      "[0.9] GENEZE new: GENZE\n",
      "[0.9] PIAGGO new: PIAGGIO\n",
      "[0.9] TOYOTOA new: TOYOTA\n",
      "[0.9] RALEIGHT new: RALEIGH\n",
      "[0.9] DIAMONDB new: DIAMOND\n",
      "[0.9] CENTURIO new: CENTURION\n",
      "[0.9] CANONDAL new: CANONDALE\n",
      "[0.9] CHRYLER new: CHRYSLER\n",
      "[0.9] HUNDAI new: HYUNDAI\n",
      "[0.9] CHYSLER new: CHRYSLER\n",
      "[0.9] PUEGOT new: PUEGEOT\n",
      "[0.9] BICYLE new: BICYCLE\n",
      "[0.9] PEUGOT new: PEUGEOT\n",
      "[0.9] SPECLZED new: SPECLIZED\n",
      "[0.9] SURLEY new: SURLY\n",
      "[0.9] CADILAC new: CADILLAC\n",
      "[0.9] SKATEBOARDER new: SKATEBOARD\n",
      "[0.9] (REFER TO NARRATIVE) new: REFER TO NARRATIVE\n",
      "[0.9] MYATA new: MIYATA\n",
      "[0.9] ANCHER new: ANCHEER\n",
      "[0.9] LAND ROVER/DEFENDER/ new: LAND ROVER/ DEFENDER\n",
      "[0.9] INIFINITI new: INFINITI\n",
      "[0.9] HON/CIV/BLU new: HON/CRV/BLU\n",
      "[0.9] LAND ROVER / RANGE ROVER /B new: LAND ROVER/RANGE ROVER/BK\n",
      "[0.9] LANDROVER/RANGEROVER/WHT new: LAND ROVER/RANGE ROVER/WH\n",
      "[0.9] LAND ROVER/RANGE ROVER/BK new: LAND ROVER/RANGE ROVER/WH\n",
      "[0.9] LANCER new: LANCE\n",
      "[0.9] CRYSLER new: CHRYSLER\n",
      "[0.9] WHEEL CHAIR new: WHEELCHAIR\n",
      "[0.9] UNKNOWN/UNKNOWN/ new: UNKNOWN/UNKNOWN\n",
      "[0.9] DUCAT new: DUCATI\n",
      "[0.9] GIANTS new: GIANT\n",
      "[0.9] PORCHE new: PORSCHE\n",
      "[0.9] TOYOT new: TOYOTA\n",
      "[0.9] UNKOWN new: UNKNOWN\n",
      "[0.9] BIANCH new: BIANCHI\n",
      "[0.9] SCHWIN new: SCHWINN\n",
      "[0.9] SPECIAL new: SPECIALI\n",
      "[0.9] SKATE BOARD new: SKATEBOARD\n",
      "[0.9] CANONDALE new: CANNONDALE\n",
      "[0.9] NISSIAN new: NISSAN\n",
      "[0.8] MERZU new: MERZ\n",
      "[0.8] 4DR new: 4 DR\n",
      "[0.8] CADICALLAC new: CADILLAC\n",
      "[0.8] GENIU new: GENU\n",
      "[0.8] TSMR/MODELS/BLU new: TSLA/MODEL S/BLU\n",
      "[0.8] ECO new: RECO\n",
      "[0.8] LEX/450H/SIL new: LEX/RX400H/SIL\n",
      "[0.8] CANNONDANE new: CANNONDALE\n",
      "[0.8] CHEVT new: CHEV\n",
      "[0.8] MOTOBECA new: MOTOBECANE\n",
      "[0.8] GENUE new: GENUINE\n",
      "[0.8] BRIDGESTONE/400/BLU new: RIDGESTONE/BLU\n",
      "[0.8] NEW new: NEWF\n",
      "[0.8] TSMR/S/WHT new: TSMR/Y/WHT\n",
      "[0.8] PEUCEOT new: PEUGEOT\n",
      "[0.8] SKBOARD new: SKATEBOARD\n",
      "[0.8] TREEK new: TREK\n",
      "[0.8] GENZ new: GENZE\n",
      "[0.8] BOOSTER new: BOOSTED\n",
      "[0.8] UNKNOWN, UNKNOWN, new: UNKNOWN/UNKNOWN\n",
      "[0.8] MAGNUM METRO new: MAGNUM METRO 750\n",
      "[0.8] DMNDBACK new: DIAMONDBACK\n",
      "[0.8] (UNKNOWN) new: UNKNOWN\n",
      "[0.8] HARLEYDAVIDSON/SPOSTER48/BL new: HARLEYDAVIDSON/ROADSTER/\n",
      "[0.8] SPECILZD new: SPECIALIZED\n",
      "[0.8] KINGSONG/ UNICYCLE new: KINGSONG UNICYCLE RE\n",
      "[0.8] CANNONDLE/SYNAPSE/W new: CANNONDAEL/SYNAPSE\n",
      "[0.8] PANTH new: PANTHER\n",
      "[0.8] UNKNOWN/UNKNOWN/UNKNOW new: UNKNOWN/UNKNOWN\n",
      "[0.8] GNUIN new: GENUINE\n",
      "[0.8] BIANXHI new: BIANCHI\n",
      "[0.8] MOTOG new: MOTO\n",
      "[0.8] LAND ROV/DISCOV/WHIT new: LAND ROVER/DISCOVERY/WHT\n",
      "[0.8] TREKA new: TREK\n",
      "[0.8] SAV WHEELS RENTAL new: BAY WHEELS RENTAL\n",
      "[0.8] ROCKHOPPER new: ROCKHOPP\n",
      "[0.8] CANNONAL new: CANNONDALE\n",
      "[0.8] MINNI new: MINI\n",
      "[0.8] HYUND new: HYUNDAI\n",
      "[0.8] UNKNOWN/UNKNOWN/BEIGE new: UNKNOWN/UNKNOWN\n",
      "[0.8] TOYTOA new: TOYOTA\n",
      "[0.8] SUZU new: ISUZU\n",
      "[0.8] CINEILI new: CINELLI\n",
      "[0.8] TSLA/MODEL S/BLU new: TESL/MODEL 3/BLU\n",
      "[0.8] BYCYCLE new: BICYCLE\n",
      "[0.8] PINACELLO new: PINARELLO\n",
      "[0.8] SPECIALEZ new: SPECIALI\n",
      "[0.8] TRU new: TRIU\n",
      "[0.8] SUBU new: SUB\n",
      "[0.8] MISHIKI new: NISHIKI\n",
      "[0.8] LANDROVER/RNGROVER new: LAND ROVER/RANGE ROVER/WH\n",
      "[0.8] LANDROVE new: LAND ROVER\n",
      "[0.8] HON/ACC/SIL new: HON/CRV/SIL\n",
      "[0.8] DACCORDI new: ACCORD\n",
      "[0.8] NUVARA new: NOVARA\n",
      "[0.8] LOADALL new: LODAL\n",
      "[0.8] TRECK new: TREK\n",
      "[0.8] APRIA new: APRILIA\n",
      "[0.8] SPART new: SPARTAN\n",
      "[0.8] NEWFL new: NEWF\n",
      "[0.8] LANDROVER/DE new: LAND ROVER\n",
      "[0.8] TOYR new: TOY\n",
      "[0.8] ALL CITY SPACE HORSE new: ALL CITY SPACE HORSE TOURING\n",
      "[0.8] CINILLI new: CINELLI\n",
      "[0.8] INTERCEPT new: INTERCEPTOR\n",
      "[0.8] SUZ new: SUZI\n",
      "[0.8] PIAGI new: PIAGGIO\n",
      "[0.8] RALIEGH new: RALEIGH\n",
      "[0.8] SPECLIZED new: SPECIALIZED\n",
      "[0.8] LANC new: LANCE\n",
      "[0.8] CHV new: CHEV\n",
      "[0.8] HYUNDIA new: HYUNDAI\n",
      "[0.8] PEUGEOT new: PUEGEOT\n",
      "[0.8] CHVY new: CHEVY\n",
      "[0.8] HON/CRV/SIL new: HON/CRV/BLU\n",
      "[0.8] GENUI new: GENUINE\n",
      "[0.8] GEN new: GENU\n",
      "[0.8] WTIN new: WTIND\n",
      "[0.8] APRLA new: APRILIA\n",
      "[0.8] LEXU new: LEXUS\n",
      "[0.8] NEOPL new: NEOPLAN\n",
      "[0.8] VESP new: VESPA\n",
      "[0.8] KYMC new: KYMCO\n",
      "[0.8] CHEVORLET new: CHEVROLET\n",
      "[0.8] BUIC new: BUICK\n",
      "[0.8] APRILLA new: APRILIA\n",
      "[0.8] GARY new: GRY\n",
      "[0.8] SCOOT new: SCOOTER\n",
      "[0.8] SUB new: SUBA\n",
      "[0.8] CANNONDA new: CANNONDALE\n",
      "[0.8] VOLV new: VOLVO\n",
      "[0.8] ACUR new: ACURA\n",
      "[0.8] MERCEDEZ new: MERCEDES\n",
      "[0.8] INFINITY new: INFINITI\n",
      "[0.8] SPECIALI new: SPECIALIZED\n",
      "[0.8] MAZD new: MAZDA\n",
      "[0.8] VOLKSWAGON new: VOLKSWAGEN\n",
      "[0.8] DODG new: DODGE\n",
      "[0.8] VOLKS new: VOLK\n",
      "[0.8] GRY new: GRAY\n",
      "[0.8] TOYO new: TOY\n",
      "[0.8] LEXS new: LEXUS\n",
      "[0.8] TOY new: TOYT\n",
      "[0.8] HOND new: HONDA\n",
      "[0.8] CHEV new: CHEVY\n",
      "[0.7] MUNIBUS new: MUNI\n",
      "[0.7] HINDA new: HONDA\n",
      "[0.7] MAGNUM/METRO 48V/ new: MAGNUM METRO 750\n",
      "[0.7] FIRD new: FORD\n",
      "[0.7] UNKNOWN/BRONZE new: UNKNOWN/MAROON\n",
      "[0.7] QUICK new: BUICK\n",
      "[0.7] TPYT new: TOYT\n",
      "[0.7] KAABO WOLF WARRIOR new: WOLF WARRIOR SCT\n",
      "[0.7] MONOTO new: MOTO\n",
      "[0.7] OXFORD new: FORD\n",
      "[0.7] NORCO new: NORTON\n",
      "[0.7] MILAN new: VILANO\n",
      "[0.7] SF TROLLEY new: TROLLEY 6\n",
      "[0.7] BRDGSTNE new: BRIDGE\n",
      "[0.7] SPCN new: SPEC\n",
      "[0.7] TYOTA/PRIUS/SIL new: TOYTOTA/4RUNNER/SIL\n",
      "[0.7] LEX/ES300/GRN new: LEX/ES300/BEIGE\n",
      "[0.7] PINA new: PINK\n",
      "[0.7] VANMOOF/X3/TEAL new: VANMOOF/X3/LIGHT BLU\n",
      "[0.7] ROCKYMOUNTAIN new: MOUNTAIN\n",
      "[0.7] PORSHE/CARRERA/WHT new: PORS/CARRERA/SIL\n",
      "[0.7] EVOLVE SKATEBOARDS new: SKATEBOARD\n",
      "[0.7] TOYOTACOROLLA/WHIT new: TOYOYA COROLLA SILV\n",
      "[0.7] SWAGTRON SWAGGER5 new: SWAGTRON/SWAGGR/BL\n",
      "[0.7] HYUNDA/ELANTA/BLAC new: HYUNDA/ELANTRA/WHIT\n",
      "[0.7] BAJA new: BAHA\n",
      "[0.7] PATHFINDER new: PANTHER\n",
      "[0.7] ROADTEK new: ROAD\n",
      "[0.7] BRAMM new: RAM\n",
      "[0.7] STRN new: SATURN\n",
      "[0.7] NASHEKE new: NASH\n",
      "[0.7] SCATTANT new: RATTAN\n",
      "[0.7] EBISU new: ISU\n",
      "[0.7] NASH new: MASH\n",
      "[0.7] WHEELER new: WHEELCHAIR\n",
      "[0.7] UNKNOWN LIMO new: UNKNOWN\n",
      "[0.7] NORTON new: ORION\n",
      "[0.7] MERLIN new: MARIN\n",
      "[0.7] XIN new: XINRI\n",
      "[0.7] MERAKI new: MASERATI\n",
      "[0.7] PISTA new: STA\n",
      "[0.7] GAZELLE / MEDEO / BLU new: GAZELLE/MEDEO T10/LIGHT BLU\n",
      "[0.7] LAPIERRE/BLU new: CAPIERRE/OVAL\n",
      "[0.7] DURA new: DUCA\n",
      "[0.7] USPS POSTAL CARRIER new: USPS - MAIL CARRIER\n",
      "[0.7] MARS new: MASI\n",
      "[0.7] MERZBENZ/S500/SIL new: MERCEDESBENZ S500 SIL\n",
      "[0.7] HYU/ ACCENT/ SIL new: HON / ACC / SIL\n",
      "[0.7] BRETA new: BREDA\n",
      "[0.7] JNANIS new: JAMIS\n",
      "[0.7] LANSTER new: PANTHER\n",
      "[0.7] RANGE ROVER/SRV/WHT new: RANGE ROVER\n",
      "[0.7] VANHL new: VAN\n",
      "[0.7] GENSE new: GENZE\n",
      "[0.7] CERVELLO new: CERVELO R5\n",
      "[0.7] CARSN new: CAR\n",
      "[0.7] RIDGEBAC new: BRIDGE\n",
      "[0.7] NINER new: INTER\n",
      "[0.7] SCHERWIN new: SCHWINN\n",
      "[0.7] GFO new: GO\n",
      "[0.7] RANGE ROVER new: LAND ROVER\n",
      "[0.7] BOOST SKATE BOARD new: SKATEBOARD\n",
      "[0.7] ECORECO new: RECO\n",
      "[0.7] JMSTA new: STA\n",
      "[0.7] SPECILIZED/VITA new: SPECIALIZED\n",
      "[0.7] HAIBIKE new: BIKE\n",
      "[0.7] WYO25 new: WY025\n",
      "[0.7] STAKEBOARD new: SKATEBOARD\n",
      "[0.7] SMARTCAR new: SMART\n",
      "[0.7] LNDROVR DISCOVER WH new: LAND ROVER/DISCOVERY/WHT\n",
      "[0.7] RALLYE new: ALLEZ\n",
      "[0.7] GOVEX new: GOVEC\n",
      "[0.7] STA new: ST\n",
      "[0.7] GRAVITY new: GRAY\n",
      "[0.7] ROYA new: ROAD\n",
      "[0.7] LAGER new: LEADER\n",
      "[0.7] HYUNDA/SONATA/BLU new: JYUNDAI/SONATA\n",
      "[0.7] FIJI new: FUJI\n",
      "[0.7] SUBAR/OUTBACK/WHT new: SBARU/OUTBACK/SILVE\n",
      "[0.7] DALTON new: DAHON\n",
      "[0.7] SPECIALIZE AMEZ new: SPECIALIZED\n",
      "[0.7] GOLDEN new: GOLD\n",
      "[0.7] OTHM new: OTHA\n",
      "[0.7] ACRUA new: ACURA\n",
      "[0.7] SEE NARRATIVE new: REFER TO NARRATIVE\n",
      "[0.7] VERSA new: VESPA\n",
      "[0.7] TEMSA new: TESLA\n",
      "[0.7] CUSHMAN new: SHIMANO\n",
      "[0.7] MASH new: MASI\n",
      "[0.7] COOLSTER new: SCOOTER\n",
      "[0.7] MERCIER new: MERCURY\n",
      "[0.7] LAND ROVER/DISCOVERY/WHT new: LAND ROVER/RANGE ROVER/WH\n",
      "[0.7] JAGU new: JAGUAR\n",
      "[0.7] PONT new: PONTIAC\n",
      "[0.7] ANCHEER new: PANTHER\n",
      "[0.7] GEO new: GO\n",
      "[0.7] BREDA new: RED\n",
      "[0.7] DIAMOND new: DIAMONDBACK\n",
      "[0.7] DUCA new: DUCATI\n",
      "[0.7] HINO new: SHIMANO\n",
      "[0.7] MNNI new: MINI\n",
      "[0.7] YAMASAKI new: YAMAHA\n",
      "[0.7] ISU new: ISUZU\n",
      "[0.7] TRIU new: TRIUMPH\n",
      "[0.7] GENU new: GENUINE\n",
      "[0.7] MERC new: MERZ\n",
      "[0.7] LINC new: LINCOLN\n",
      "[0.7] SUZI new: SUZUKI\n",
      "[0.7] YAMA new: YAMAHA\n",
      "[0.7] INFI new: MINI\n",
      "[0.7] CADI new: AUDI\n",
      "[0.7] SUBA new: SUBARU\n",
      "[0.7] WHI new: WHITE\n",
      "[0.7] ISUZU new: SUZUKI\n",
      "[0.7] MUNI new: MINI\n",
      "[0.7] GREY new: GRAY\n",
      "[0.7] HYUN new: HYUNDAI\n",
      "[0.7] NISS new: NISSAN\n",
      "[0.7] BLK new: BLACK\n",
      "[0.7] TOYT new: TOYOTA\n"
     ]
    }
   ],
   "source": [
    "# replace similar values:\n",
    "for threshold in [0.9, 0.8, 0.7]:\n",
    "    values = df['vehicle_make'].value_counts().index\n",
    "    for i in reversed(range(len(values))):\n",
    "        old_value = values[i]\n",
    "        for j in range(0, i):\n",
    "            new_value = values[j]\n",
    "            ratio = difflib.SequenceMatcher(None, old_value, new_value).ratio()\n",
    "            if ratio > threshold and ratio < 1:\n",
    "                print(\"[\" + str(threshold) + \"] \" + old_value + \" new: \" + new_value)            \n",
    "                df.loc[df['vehicle_make'] == old_value, 'vehicle_make'] = new_value\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "0f76626c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vehicle_make\n",
       "TOYOTA       8426\n",
       "UNKNOWN      8138\n",
       "HONDA        5267\n",
       "FORD         3544\n",
       "NISSAN       2154\n",
       "BLACK        1448\n",
       "BMW          1394\n",
       "LEXUS        1111\n",
       "HYUNDAI      1023\n",
       "CHEVY         988\n",
       "WHITE         920\n",
       "DODGE         851\n",
       "CHEVROLET     765\n",
       "BICYCLE       644\n",
       "MAZDA         627\n",
       "ACURA         616\n",
       "SUBARU        606\n",
       "SCOOTER       597\n",
       "MERCEDES      561\n",
       "JEEP          536\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['vehicle_make'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "b7344c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "663"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['vehicle_make'].value_counts().shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef698822",
   "metadata": {},
   "source": [
    "It is likely this caused some miscategorizations, and the result could be further improved by manually checking values. Nevertheless, it is in better shape than the original data. We stop it here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0233a2c",
   "metadata": {},
   "source": [
    "Whereas `UNKNOWN` was easier to work with, we will change that to the usual `Not Stated`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "69017b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['vehicle_make'] == 'UNKNOWN', 'vehicle_make'] = 'Not Stated'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917784b1",
   "metadata": {},
   "source": [
    "## Column `stwd_vehicle_type`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "7f5e7f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stwd_vehicle_type\n",
       "Passenger Car                                                                       30266\n",
       "Pedestrian                                                                           6252\n",
       "Bicycle                                                                              4020\n",
       "Sport Utility Vehicle                                                                2480\n",
       "Motorcycle                                                                           2171\n",
       "                                                                                    ...  \n",
       "Dune Buggy                                                                              1\n",
       "Pickup and Camper (Hazardous Waste or Hazardous Waste/Material Combination)             1\n",
       "Trailer Coach                                                                           1\n",
       "Container Chassis                                                                       1\n",
       "Truck or Truck Tractor (Hazardous Waste or Hazardous Waste/Material Combination)        1\n",
       "Name: count, Length: 71, dtype: int64"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['stwd_vehicle_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "96a60817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['stwd_vehicle_type'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "98dbaa37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stwd_vehicle_type\n",
       "Passenger Car                               30266\n",
       "Pedestrian                                   6252\n",
       "Bicycle                                      4020\n",
       "Sport Utility Vehicle                        2480\n",
       "Motorcycle                                   2171\n",
       "Pickup or Panel Truck                        1317\n",
       "Motor Driven Cycle/Scooter                    902\n",
       "Go-ped, ZIP Electric Scooter, Motorboard      807\n",
       "Minivan                                       761\n",
       "Other Bus                                     332\n",
       "Unknown Hit and Run                           180\n",
       "Public Transit Authority                      162\n",
       "Paratransit                                   157\n",
       "All Terrain Vehicle                           149\n",
       "Two Axle Truck                                140\n",
       "Other Commercial                              134\n",
       "Not Stated                                    131\n",
       "Truck                                         128\n",
       "Emergency Vehicle                             126\n",
       "Police Car                                     87\n",
       "Misc. Motor Vehicle                            70\n",
       "Unknown                                        68\n",
       "Semi                                           53\n",
       "Motorized Bicycle                              51\n",
       "Three or More Axle Truck                       49\n",
       "Misc. Non-Motor Vehicle                        46\n",
       "Electric Bicycle                               42\n",
       "Two Axle Tank Truck                            39\n",
       "Truck or Truck Tractor                         38\n",
       "Other                                          34\n",
       "Low Speed Vehicle                              30\n",
       "Pickup or Panel Truck with Trailer             27\n",
       "Fire Truck                                     25\n",
       "Two Axle Tow Truck                             22\n",
       "Ambulance                                      22\n",
       "Electrically Motorized Board                   21\n",
       "Utility                                        19\n",
       "Truck with Trailer                             17\n",
       "Tour Bus                                       17\n",
       "Fork Lift                                      16\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['stwd_vehicle_type'].value_counts().head(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3249f2a8",
   "metadata": {},
   "source": [
    "`Unknown` and `Not Stated` are values. We will merge them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "ad35d6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['stwd_vehicle_type'] == 'Unknown', 'stwd_vehicle_type'] = 'Not Stated'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fec9b7",
   "metadata": {},
   "source": [
    "## Column `race`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "9f6aa58d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "race\n",
       "White         15754\n",
       "Hispanic       9549\n",
       "Asian          8737\n",
       "Black          6763\n",
       "Not Stated     6083\n",
       "Other          4645\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['race'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "32a9fc0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['race'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b812692f",
   "metadata": {},
   "source": [
    "Nothing to do here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b53b968",
   "metadata": {},
   "source": [
    "## Column `inattention`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "a3854475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inattention\n",
       "Not Stated                     49947\n",
       "Cell Phone Not In Use           1392\n",
       "Other                             89\n",
       "Cellphone Handheld                24\n",
       "Cell Phone Handsfree In Use       15\n",
       "Cell Phone Handheld In Use        10\n",
       "Electronic Equipment               7\n",
       "Eating                             5\n",
       "Cellphone Handsfree                5\n",
       "Hazardous Material                 5\n",
       "32 Ft Trailer Combo                5\n",
       "Animals                            4\n",
       "Smoking                            2\n",
       "Radio/CD                           2\n",
       "School Bus Related                 1\n",
       "Children                           1\n",
       "Unknown                            1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['inattention'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6fa626",
   "metadata": {},
   "source": [
    "Another column with very few values, we will drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "b3e251cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='inattention', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbeab72",
   "metadata": {},
   "source": [
    "## Columns `special_info_f` and `special_info_g`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "81582e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "special_info_f\n",
       "Not Stated    16804\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['special_info_f'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "d8ea1ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "special_info_g\n",
       "Not Stated    16804\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['special_info_g'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d173d3",
   "metadata": {},
   "source": [
    "No information here, we drop the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "79450fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['special_info_f', 'special_info_g'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135b1130",
   "metadata": {},
   "source": [
    "## Column `street_of_travel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "09fb8021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "street_of_travel\n",
       "MISSION ST            1338\n",
       "MARKET ST              854\n",
       "GEARY BLVD             626\n",
       "MISSION STREET         609\n",
       "VAN NESS AVE           576\n",
       "                      ... \n",
       "44TH AVE FULTON          1\n",
       "MISSION STREET`          1\n",
       "28TH                     1\n",
       "HUNTERS EXPRESSWAY       1\n",
       "CLARENDON AVENUE         1\n",
       "Name: count, Length: 3861, dtype: int64"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['street_of_travel'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "ce72bb08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2022"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['street_of_travel'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d757f5c",
   "metadata": {},
   "source": [
    "Similar adjustments could be done like for columns `primary_rd` and `secondary_rd`. We only adjust the nulls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "e75f141d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['street_of_travel'].str.upper() == 'UNKNOWN', 'street_of_travel'] = 'Not Stated'\n",
    "df.loc[df['street_of_travel'].str.upper() == 'NOT STATED', 'street_of_travel'] = 'Not Stated'\n",
    "df.loc[df['street_of_travel'].isna(), 'street_of_travel'] = 'Not Stated'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08862d3f",
   "metadata": {},
   "source": [
    "## Column `vehicle_autonomous`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "7ed46cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vehicle_autonomous\n",
       "Not applicable, conventional vehicle                                       18856\n",
       "Not Stated                                                                 16378\n",
       "Not Collected                                                              16192\n",
       "Autonomous vehicle operating under driver control at time of collision        76\n",
       "Operating in autonomous mode at time of collision with a driver present       11\n",
       "Driverless vehicle with passenger only, no driver override possible           11\n",
       "Autopilot engaged (autoparking, etc.) with driver present                      7\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['vehicle_autonomous'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3434cb0",
   "metadata": {},
   "source": [
    "There are hardly any autonomous vehicle to be a meaningful sample, so we will remove the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "40163cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='vehicle_autonomous', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c662668e",
   "metadata": {},
   "source": [
    "## Column `Current Police Districts`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "c12cf0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Current Police Districts\n",
       "1.0     7126\n",
       "2.0     5214\n",
       "3.0     7315\n",
       "4.0     7862\n",
       "5.0     2869\n",
       "6.0     4671\n",
       "7.0     2247\n",
       "8.0     3809\n",
       "9.0     5014\n",
       "10.0    5238\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Current Police Districts'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "4766ea7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Current Police Districts'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1c6c2a",
   "metadata": {},
   "source": [
    "The values are as expected, but should be converted to Integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "84a264d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Current Police Districts'] = df['Current Police Districts'].astype(pd.Int64Dtype())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4781ccad",
   "metadata": {},
   "source": [
    "## Column `Current Supervisor Districts`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "6d46edd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Current Supervisor Districts\n",
       "1.0      3254\n",
       "2.0      5487\n",
       "3.0      4487\n",
       "4.0      3524\n",
       "5.0      3857\n",
       "6.0      3508\n",
       "7.0      1730\n",
       "8.0      3017\n",
       "9.0      5799\n",
       "10.0    10911\n",
       "11.0     5807\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Current Supervisor Districts'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "d8d71aaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Current Supervisor Districts'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42b747c",
   "metadata": {},
   "source": [
    "Like the previous column, we need to convert to integer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "132d0247",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Current Supervisor Districts'] = df['Current Supervisor Districts'].astype(pd.Int64Dtype())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4962b990",
   "metadata": {},
   "source": [
    "# New column: `vehicle_age`\n",
    "To facilitate the analysis, we create a new columm `vehicle_age` as the difference between the year of the collision, and the `vehicle_year`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "80a779fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vehicle_age'] = (df['collision_datetime'].dt.year-df['vehicle_year']).astype(pd.Int64Dtype())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795f5216",
   "metadata": {},
   "source": [
    "# Format output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dbd665",
   "metadata": {},
   "source": [
    "To prepare the DataFrame to export as a CSV, we will reorder the columns and export as CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "f33ff61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_reordered = ['case_id_pkey', 'tb_latitude', 'tb_longitude', 'collision_datetime',\n",
    "       'officer_id', 'primary_rd', 'secondary_rd', 'distance', 'direction',\n",
    "       'weather_1', 'weather_2', 'collision_severity', 'type_of_collision',\n",
    "       'mviw', 'ped_action', 'road_surface', 'road_cond_1', 'road_cond_2',\n",
    "       'lighting', 'control_device', 'vz_pcf_description',\n",
    "       'dph_col_grp_description', 'party_number_ckey', 'party_type',\n",
    "       'at_fault', 'party_sex', 'party_age', 'race', 'party_sobriety',\n",
    "       'party_safety_equip_1', 'party_safety_equip_2', 'finan_respons',\n",
    "       'party_number_killed', 'party_number_injured', 'move_pre_acc',\n",
    "       'vehicle_year', 'vehicle_make', 'vehicle_age', 'stwd_vehicle_type',\n",
    "       'dir_of_travel', 'street_of_travel', 'Current Police Districts',\n",
    "       'Current Supervisor Districts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "2f68e93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_output = 'sf_traffic.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "6d822671",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[columns_reordered].to_csv(file_name_output, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e40310",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
